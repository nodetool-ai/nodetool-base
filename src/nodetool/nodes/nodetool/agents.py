from enum import Enum
from typing import Any, AsyncGenerator, List, Optional, Union
from pydantic import Field

from nodetool.chat.cot_agent import (
    TaskPlanner,
    TaskExecutor,
    DEFAULT_PLANNING_SYSTEM_PROMPT,
    DEFAULT_EXECUTION_SYSTEM_PROMPT,
)
from nodetool.chat.providers import Chunk, AnthropicProvider
from nodetool.chat.tools.base import get_tool_by_name, Tool
from nodetool.metadata.types import (
    Message,
    ToolCall,
    TaskPlan,
    FunctionModel,
    AgentModel,
    ToolName,
)
from nodetool.workflows.base_node import BaseNode
from nodetool.workflows.processing_context import ProcessingContext
from nodetool.workflows.types import NodeProgress


def init_tool(tool: ToolName, workspace_dir: str) -> Optional[Tool]:
    if tool.name:
        tool_class = get_tool_by_name(tool.name)
        if tool_class:
            return tool_class(workspace_dir)
        else:
            return None
    else:
        return None


def provider_from_model(model: FunctionModel) -> AnthropicProvider:
    if model.name.startswith("claude"):
        return AnthropicProvider()
    else:
        raise ValueError(f"Unsupported model: {model.name}")


class AgentPlanner(BaseNode):
    """
    Plans tasks using Chain of Thought (CoT) agent powered by Anthropic's Claude.
    agent, planning, tasks, anthropic, claude

    Use cases:
    - Break down complex problems into steps
    - Create structured task lists with dependencies
    - Generate plans for automated processes
    - Prepare task sequences for execution
    """

    objective: str = Field(
        default="", description="The objective or problem to create a plan for"
    )

    model: AgentModel = Field(
        default=AgentModel.claude_3_7_sonnet,
        description="Model to use for planning",
    )

    tools: List[ToolName] = Field(
        default=[], description="List of tools to use for planning"
    )

    workspace_dir: str = Field(
        default="/tmp/agent-workspace", description="Directory for workspace files"
    )

    system_prompt: str = Field(
        default=DEFAULT_PLANNING_SYSTEM_PROMPT,
        description="Optional custom system prompt for planning",
    )

    async def process(self, context: ProcessingContext) -> TaskPlan:
        if not self.objective:
            raise ValueError("Objective cannot be empty")

        # Set up provider and tools
        if (
            self.model == AgentModel.claude_3_7_sonnet
            or self.model == AgentModel.claude_3_5_sonnet
        ):
            provider = AnthropicProvider()
        else:
            raise ValueError(f"Unsupported model: {self.model}")

        tools = [init_tool(tool, self.workspace_dir) for tool in self.tools]

        # Create the task planner
        planner = TaskPlanner(
            provider=provider,
            model=FunctionModel(name=self.model.value),
            objective=self.objective,
            system_prompt=self.system_prompt,
        )

        # Generate the plan
        async for result in planner.create_plan():
            if isinstance(result, Chunk):
                context.post_message(
                    NodeProgress(
                        node_id=self.id,
                        progress=0,
                        total=0,
                        chunk=result.content,
                    )
                )

        assert (
            planner.task_plan is not None
        ), "Task plan should be generated by the planner"

        return planner.task_plan


class AgentExecutor(BaseNode):
    """
    Executes tasks using Chain of Thought (CoT) agent powered by Anthropic's Claude.
    agent, execution, tasks, anthropic, claude

    Use cases:
    - Execute task lists generated by the planner
    - Automate complex workflows with reasoning
    - Process tasks with tool calling capabilities
    - Solve problems step-by-step with LLM reasoning
    """

    task_plan: TaskPlan = Field(
        default=TaskPlan(title="Empty Plan"),
        description="The task plan to execute",
    )

    model: AgentModel = Field(
        default=AgentModel.claude_3_7_sonnet,
        description="Anthropic model to use for execution",
    )

    tools: List[ToolName] = Field(
        default=[], description="List of tools to use for execution"
    )

    workspace_dir: str = Field(
        default="/tmp/agent-workspace", description="Directory for workspace files"
    )

    system_prompt: Optional[str] = Field(
        default=DEFAULT_EXECUTION_SYSTEM_PROMPT,
        description="Optional custom system prompt for execution",
    )

    max_steps: int = Field(
        default=30, description="Maximum execution steps to prevent infinite loops"
    )

    @classmethod
    def return_type(cls):
        return {
            "task_plan": TaskPlan,
            "messages": list[Message],
        }

    async def process(self, context: ProcessingContext) -> list[Message]:
        if not self.task_plan or not self.task_plan.tasks:
            raise ValueError("Task list cannot be empty")

        # Set up provider and function model
        provider = AnthropicProvider()
        model = FunctionModel(name=self.model.value)

        tools = [init_tool(tool, self.workspace_dir) for tool in self.tools]

        # Create the task executor
        executor = TaskExecutor(
            provider=provider,
            model=model,
            workspace_dir=self.workspace_dir,
            tools=[tool for tool in tools if tool is not None],
            task_plan=self.task_plan,
            system_prompt=self.system_prompt,
            max_steps=self.max_steps,
        )

        # Execute tasks and collect results
        messages = []
        async for result in executor.execute_tasks():
            # Convert chunks to messages for easier consumption
            if isinstance(result, Chunk):
                messages.append(Message(role="assistant", content=result.content))
                context.post_message(
                    NodeProgress(
                        node_id=self.id,
                        progress=0,
                        total=0,
                        chunk=result.content,
                    )
                )
            elif isinstance(result, Message):
                messages.append(result)
            elif isinstance(result, ToolCall):
                messages.append(
                    Message(
                        role="assistant",
                        tool_calls=[result],
                    )
                )

        # Return the execution results
        return messages
