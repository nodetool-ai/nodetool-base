# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode

import nodetool.nodes.gemini.video
import nodetool.nodes.gemini.video


class ImageToVideo(GraphNode):
    """
    Generate videos from images using Google's Veo models.
    google, video, generation, image-to-video, veo, ai, animation

    This node uses Google's Veo models to animate static images into dynamic videos.
    Supports 720p resolution at 24fps with 8-second duration and native audio generation.

    Use cases:
    - Animate still artwork and photographs
    - Create dynamic social media content from images
    - Generate product showcase videos from photos
    - Transform static graphics into engaging animations
    - Create video presentations from slide images
    """

    VeoModel: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoModel
    VeoAspectRatio: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoAspectRatio
    image: types.ImageRef | GraphNode | tuple[GraphNode, str] = Field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to animate into a video",
    )
    prompt: str | GraphNode | tuple[GraphNode, str] = Field(
        default="", description="Optional text prompt describing the desired animation"
    )
    model: nodetool.nodes.gemini.video.VeoModel = Field(
        default=nodetool.nodes.gemini.video.VeoModel.VEO_3_PREVIEW,
        description="The Veo model to use for video generation",
    )
    aspect_ratio: nodetool.nodes.gemini.video.VeoAspectRatio = Field(
        default=nodetool.nodes.gemini.video.VeoAspectRatio.RATIO_16_9,
        description="The aspect ratio of the generated video",
    )
    negative_prompt: str | GraphNode | tuple[GraphNode, str] = Field(
        default="", description="Negative prompt to guide what to avoid in the video"
    )

    @classmethod
    def get_node_type(cls):
        return "gemini.video.ImageToVideo"


import nodetool.nodes.gemini.video
import nodetool.nodes.gemini.video


class TextToVideo(GraphNode):
    """
    Generate videos from text prompts using Google's Veo models.
    google, video, generation, text-to-video, veo, ai

    This node uses Google's Veo models to generate high-quality videos from text descriptions.
    Supports 720p resolution at 24fps with 8-second duration and native audio generation.

    Use cases:
    - Create cinematic clips from text descriptions
    - Generate social media video content
    - Produce marketing and promotional videos
    - Visualize creative concepts and storyboards
    - Create animated content with accompanying audio
    """

    VeoModel: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoModel
    VeoAspectRatio: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoAspectRatio
    prompt: str | GraphNode | tuple[GraphNode, str] = Field(
        default="", description="The text prompt describing the video to generate"
    )
    model: nodetool.nodes.gemini.video.VeoModel = Field(
        default=nodetool.nodes.gemini.video.VeoModel.VEO_3_PREVIEW,
        description="The Veo model to use for video generation",
    )
    aspect_ratio: nodetool.nodes.gemini.video.VeoAspectRatio = Field(
        default=nodetool.nodes.gemini.video.VeoAspectRatio.RATIO_16_9,
        description="The aspect ratio of the generated video",
    )
    negative_prompt: str | GraphNode | tuple[GraphNode, str] = Field(
        default="", description="Negative prompt to guide what to avoid in the video"
    )

    @classmethod
    def get_node_type(cls):
        return "gemini.video.TextToVideo"
