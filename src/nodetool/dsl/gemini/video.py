# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import Field
import typing
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

from nodetool.dsl.handles import OutputHandle, connect_field
import nodetool.nodes.gemini.video
from nodetool.workflows.base_node import BaseNode


class ImageToVideo(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Generate videos from images using Google's Veo models.
    google, video, generation, image-to-video, veo, ai, animation

    This node uses Google's Veo models to animate static images into dynamic videos.
    Supports 720p resolution at 24fps with 8-second duration and native audio generation.

    Use cases:
    - Animate still artwork and photographs
    - Create dynamic social media content from images
    - Generate product showcase videos from photos
    - Transform static graphics into engaging animations
    - Create video presentations from slide images
    """

    VeoModel: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoModel
    VeoAspectRatio: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoAspectRatio

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(type="image", uri="", asset_id=None, data=None),
        description="The image to animate into a video",
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="Optional text prompt describing the desired animation"
    )
    model: nodetool.nodes.gemini.video.VeoModel = Field(
        default=nodetool.nodes.gemini.video.VeoModel.VEO_3_PREVIEW,
        description="The Veo model to use for video generation",
    )
    aspect_ratio: nodetool.nodes.gemini.video.VeoAspectRatio = Field(
        default=nodetool.nodes.gemini.video.VeoAspectRatio.RATIO_16_9,
        description="The aspect ratio of the generated video",
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Negative prompt to guide what to avoid in the video"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.gemini.video.ImageToVideo

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, connect_field
import nodetool.nodes.gemini.video
from nodetool.workflows.base_node import BaseNode


class TextToVideo(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Generate videos from text prompts using Google's Veo models.
    google, video, generation, text-to-video, veo, ai

    This node uses Google's Veo models to generate high-quality videos from text descriptions.
    Supports 720p resolution at 24fps with 8-second duration and native audio generation.

    Use cases:
    - Create cinematic clips from text descriptions
    - Generate social media video content
    - Produce marketing and promotional videos
    - Visualize creative concepts and storyboards
    - Create animated content with accompanying audio
    """

    VeoModel: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoModel
    VeoAspectRatio: typing.ClassVar[type] = nodetool.nodes.gemini.video.VeoAspectRatio

    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the video to generate"
    )
    model: nodetool.nodes.gemini.video.VeoModel = Field(
        default=nodetool.nodes.gemini.video.VeoModel.VEO_3_PREVIEW,
        description="The Veo model to use for video generation",
    )
    aspect_ratio: nodetool.nodes.gemini.video.VeoAspectRatio = Field(
        default=nodetool.nodes.gemini.video.VeoAspectRatio.RATIO_16_9,
        description="The aspect ratio of the generated video",
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Negative prompt to guide what to avoid in the video"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.gemini.video.TextToVideo

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
