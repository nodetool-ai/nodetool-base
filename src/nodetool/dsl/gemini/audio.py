# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.gemini.audio
from nodetool.workflows.base_node import BaseNode


class TextToSpeech(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

    Generate speech audio from text using Google's Gemini text-to-speech models.
    google, text-to-speech, tts, audio, speech, voice, ai

    This node converts text input into natural-sounding speech audio using Google's
    advanced text-to-speech models with support for multiple voices and speech styles.

    Supported voices:
    - achernar, achird, algenib, algieba, alnilam
    - aoede, autonoe, callirrhoe, charon, despina
    - enceladus, erinome, fenrir, gacrux, iapetus
    - kore, laomedeia, leda, orus, puck
    - pulcherrima, rasalgethi, sadachbia, sadaltager, schedar
    - sulafat, umbriel, vindemiatrix, zephyr, zubenelgenubi

    Use cases:
    - Create voiceovers for videos and presentations
    - Generate audio content for podcasts and audiobooks
    - Add voice narration to applications
    - Create accessibility features with speech output
    - Generate multilingual audio content
    """

    TTSModel: typing.ClassVar[type] = nodetool.nodes.gemini.audio.TTSModel
    VoiceName: typing.ClassVar[type] = nodetool.nodes.gemini.audio.VoiceName

    text: str | OutputHandle[str] = connect_field(
        default="", description="The text to convert to speech."
    )
    model: nodetool.nodes.gemini.audio.TTSModel = Field(
        default=nodetool.nodes.gemini.audio.TTSModel.GEMINI_2_5_PRO_PREVIEW_TTS,
        description="The text-to-speech model to use",
    )
    voice_name: nodetool.nodes.gemini.audio.VoiceName = Field(
        default=nodetool.nodes.gemini.audio.VoiceName.KORE,
        description="The voice to use for speech generation",
    )
    style_prompt: str | OutputHandle[str] = connect_field(
        default="",
        description="Optional style prompt to control speech characteristics (e.g., 'Say cheerfully', 'Speak with excitement')",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.gemini.audio.TextToSpeech

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.gemini.audio
from nodetool.workflows.base_node import BaseNode


class Transcribe(SingleOutputGraphNode[str], GraphNode[str]):
    """

    Transcribe audio to text using Google's Gemini models.
    google, transcription, speech-to-text, audio, whisper, ai

    This node converts audio input into text using Google's multimodal Gemini models.
    Supports various audio formats and provides accurate speech-to-text transcription.

    Use cases:
    - Convert recorded audio to text
    - Transcribe podcasts and interviews
    - Generate subtitles from audio tracks
    - Create meeting notes from audio recordings
    - Analyze speech content in audio files
    """

    TranscriptionModel: typing.ClassVar[type] = (
        nodetool.nodes.gemini.audio.TranscriptionModel
    )

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The audio file to transcribe.",
    )
    model: nodetool.nodes.gemini.audio.TranscriptionModel = Field(
        default=nodetool.nodes.gemini.audio.TranscriptionModel.GEMINI_2_5_FLASH,
        description="The Gemini model to use for transcription",
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="Transcribe the following audio accurately. Return only the transcription text without any additional commentary.",
        description="Instructions for the transcription. You can customize this to request specific formatting or focus.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.gemini.audio.Transcribe

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
