# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class ByteDanceSeedream(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using ByteDance's Seedream model via Kie.ai.

        kie, seedream, bytedance, image generation, ai, text-to-image, 3d, 2d

        Seedream generates high-quality images with support for both 2D and 3D styles.
        It excels at creating artistic illustrations, designs, and visual content.

        Use cases:
        - Generate 2D flat art illustrations
        - Create 3D style images
        - Design posters and marketing materials
        - Generate artistic content in various styles
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.ByteDanceSeedream.ImageSize

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    image_size: nodetool.nodes.kie.image.ByteDanceSeedream.ImageSize = Field(default=nodetool.nodes.kie.image.ByteDanceSeedream.ImageSize.SQUARE_HD, description='The resolution/aspect ratio of the generated image.')
    guidance_scale: float | OutputHandle[float] = connect_field(default=2.5, description='Controls how closely the output aligns with the prompt. Range: 1-10.')
    seed: int | OutputHandle[int] = connect_field(default=0, description='Random seed for reproducible results. Use 0 for random.')
    enable_safety_checker: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to enable safety checking on generated images.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.ByteDanceSeedream

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Flux2FlexImageToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux 2 Flex Image-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-flex, black-forest-labs, image generation, ai, image-to-image

        Use cases:
        - Transform existing images with text prompts
        - Apply artistic styles to photos
        - Create variations of existing images
        - Enhance and modify images
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio
    Resolution: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing how to transform the image.')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The source image to transform.')
    aspect_ratio: nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    resolution: nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution = Field(default=nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution.RES_1K, description='Output image resolution.')
    steps: int | OutputHandle[int] = connect_field(default=25, description='Number of inference steps. Higher values may produce better quality but take longer.')
    guidance_scale: float | OutputHandle[float] = connect_field(default=7.5, description='Guidance scale for the generation. Higher values adhere more closely to the prompt.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2FlexImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Flux2FlexTextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux 2 Flex Text-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-flex, black-forest-labs, image generation, ai, text-to-image

        Use cases:
        - Generate high-quality images from text with flexible parameters
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio
    Resolution: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    resolution: nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution = Field(default=nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution.RES_1K, description='Output image resolution.')
    steps: int | OutputHandle[int] = connect_field(default=25, description='Number of inference steps. Higher values may produce better quality but take longer.')
    guidance_scale: float | OutputHandle[float] = connect_field(default=7.5, description='Guidance scale for the generation. Higher values adhere more closely to the prompt.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2FlexTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Flux2ProImageToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux 2 Pro Image-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-pro, black-forest-labs, image generation, ai, image-to-image

        Use cases:
        - Transform existing images with text prompts
        - Apply artistic styles to photos
        - Create variations of existing images
        - Enhance and modify images
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio
    Resolution: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing how to transform the image.')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The source image to transform.')
    aspect_ratio: nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    resolution: nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution = Field(default=nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution.RES_1K, description='Output image resolution.')
    steps: int | OutputHandle[int] = connect_field(default=25, description='Number of inference steps. Higher values may produce better quality but take longer.')
    guidance_scale: float | OutputHandle[float] = connect_field(default=7.5, description='Guidance scale for the generation. Higher values adhere more closely to the prompt.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2ProImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Flux2ProTextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux 2 Pro Text-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-pro, black-forest-labs, image generation, ai, text-to-image

        Use cases:
        - Generate high-quality artistic images from text
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio
    Resolution: typing.ClassVar[type] = nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    resolution: nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution = Field(default=nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution.RES_1K, description='Output image resolution.')
    steps: int | OutputHandle[int] = connect_field(default=25, description='Number of inference steps. Higher values may produce better quality but take longer.')
    guidance_scale: float | OutputHandle[float] = connect_field(default=7.5, description='Guidance scale for the generation. Higher values adhere more closely to the prompt.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2ProTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class FluxKontext(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux Kontext model via Kie.ai.

        kie, flux, flux-kontext, black-forest-labs, image generation, ai, text-to-image, editing

        Flux Kontext supports Pro (speed-optimized) and Max (quality-focused) variants
        with features like multiple aspect ratios, safety controls, and async processing.

        Use cases:
        - Generate high-quality artistic images
        - Advanced image editing and generation
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.FluxKontext.AspectRatio
    Mode: typing.ClassVar[type] = nodetool.nodes.kie.image.FluxKontext.Mode

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.FluxKontext.AspectRatio = Field(default=nodetool.nodes.kie.image.FluxKontext.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    mode: nodetool.nodes.kie.image.FluxKontext.Mode = Field(default=nodetool.nodes.kie.image.FluxKontext.Mode.PRO, description="Generation mode: 'pro' for speed, 'max' for quality.")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.FluxKontext

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class GrokImagineTextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using xAI's Grok Imagine Text-to-Image model via Kie.ai.

        kie, grok, xai, image generation, ai, text-to-image, multimodal

        Grok Imagine is a multimodal generative model that can generate images
        from text prompts.

        Use cases:
        - Generate images from text descriptions
        - Create visual content with AI
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GrokImagineTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class GrokImagineUpscale(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Upscale images using xAI's Grok Imagine Upscale model via Kie.ai.

        kie, grok, xai, upscale, enhance, image, ai, super-resolution

        Grok Imagine Upscale enhances and upscales images to higher resolutions
        while maintaining quality and detail.

        Constraints:
        - Only images generated by Kie AI models (via Grok Imagine) are supported for upscaling.
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to upscale. Must be an image previously generated by a Kie.ai node.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GrokImagineUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class IdeogramCharacterRemix(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Remix characters in images using Ideogram via Kie.ai.

        kie, ideogram, character-remix, image generation, ai, remix

        Ideogram Character Remix allows you to remix images while maintaining character consistency
        using reference images and text prompts.
    """

    RenderingSpeed: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramCharacterRemix.Style
    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize

    prompt: str | OutputHandle[str] = connect_field(default='', description='Text description for remixing.')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Base image to remix.')
    reference_images: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=[], description='Reference images for character guidance.')
    rendering_speed: nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed = Field(default=nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed.BALANCED, description='Rendering speed preference.')
    style: nodetool.nodes.kie.image.IdeogramCharacterRemix.Style = Field(default=nodetool.nodes.kie.image.IdeogramCharacterRemix.Style.AUTO, description='Generation style.')
    expand_prompt: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to expand/augment the prompt.')
    image_size: nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize = Field(default=nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize.SQUARE_HD, description='The size of the output image.')
    strength: float | OutputHandle[float] = connect_field(default=0.8, description='How strongly to apply the remix (0.0 to 1.0).')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Undesired elements to exclude from the image.')
    additional_images: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=[], description='Additional image inputs.')
    reference_mask_urls: str | OutputHandle[str] = connect_field(default='', description='URL(s) to masks for references (comma-separated).')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramCharacterRemix

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class IdeogramV3Reframe(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Reframe images using Ideogram v3 via Kie.ai.

        kie, ideogram, v3-reframe, image processing, ai, reframe

        Use cases:
        - Reframe and rescale existing images
        - Change aspect ratio of images while maintaining quality
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize
    RenderingSpeed: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3Reframe.Style

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL of the image to reframe.')
    image_size: nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize = Field(default=nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize.SQUARE_HD, description='Output resolution preset.')
    rendering_speed: nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed = Field(default=nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed.BALANCED, description='Rendering speed preference.')
    style: nodetool.nodes.kie.image.IdeogramV3Reframe.Style = Field(default=nodetool.nodes.kie.image.IdeogramV3Reframe.Style.AUTO, description='Generation style.')
    seed: int | OutputHandle[int] = connect_field(default=0, description='RNG seed.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramV3Reframe

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class IdeogramV3TextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Ideogram's V3 Text-to-Image model via Kie.ai.

        kie, ideogram, v3, image generation, ai, text-to-image, design

        Ideogram V3 generates high-quality images from text prompts with
        excellent design and typography capabilities.

        Use cases:
        - Generate images with embedded text
        - Create professional designs and graphics
        - Generate artistic images with typography
    """

    RenderingSpeed: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3TextToImage.Style
    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3TextToImage.ImageSize

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    rendering_speed: nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed = Field(default=nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed.BALANCED, description='Rendering speed preference: TURBO (fastest), BALANCED, QUALITY (slowest).')
    style: nodetool.nodes.kie.image.IdeogramV3TextToImage.Style = Field(default=nodetool.nodes.kie.image.IdeogramV3TextToImage.Style.AUTO, description='Generation style: AUTO, GENERAL, REALISTIC, or DESIGN.')
    expand_prompt: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to use MagicPrompt to enhance the prompt.')
    image_size: nodetool.nodes.kie.image.IdeogramV3TextToImage.ImageSize = Field(default=nodetool.nodes.kie.image.IdeogramV3TextToImage.ImageSize.SQUARE_HD, description='The resolution/aspect ratio of the generated image.')
    seed: int | OutputHandle[int] = connect_field(default=0, description='Random seed for reproducible results. Use 0 for random.')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Description of what to exclude from the image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramV3TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Imagen4(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 model via Kie.ai.

        kie, google, imagen, imagen4, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Imagen4.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Undesired elements to exclude.')
    aspect_ratio: nodetool.nodes.kie.image.Imagen4.AspectRatio = Field(default=nodetool.nodes.kie.image.Imagen4.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    seed: int | OutputHandle[int] = connect_field(default=0, description='RNG seed.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Imagen4Fast(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 Fast model via Kie.ai.

        kie, google, imagen, imagen4, fast, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Imagen4Fast.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Undesired elements to exclude.')
    aspect_ratio: nodetool.nodes.kie.image.Imagen4Fast.AspectRatio = Field(default=nodetool.nodes.kie.image.Imagen4Fast.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4Fast

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Imagen4Ultra(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 Ultra model via Kie.ai.

        kie, google, imagen, imagen4, ultra, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Undesired elements to exclude.')
    aspect_ratio: nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio = Field(default=nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    seed: int | OutputHandle[int] = connect_field(default=0, description='RNG seed.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4Ultra

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class NanoBanana(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Nano Banana model (Gemini 2.5) via Kie.ai.

        kie, nano-banana, google, gemini, image generation, ai, text-to-image, fast
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBanana.ImageSize

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    image_size: nodetool.nodes.kie.image.NanoBanana.ImageSize = Field(default=nodetool.nodes.kie.image.NanoBanana.ImageSize.SQUARE, description='The size of the output image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBanana

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class NanoBananaEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Edit images using Google's Nano Banana model via Kie.ai.

        kie, google, nano-banana, nano-banana-edit, image editing, ai
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBananaEdit.ImageSize

    prompt: str | OutputHandle[str] = connect_field(default='', description='Text description of the changes to make.')
    image_input: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=[], description='Images to edit.')
    image_size: nodetool.nodes.kie.image.NanoBananaEdit.ImageSize = Field(default=nodetool.nodes.kie.image.NanoBananaEdit.ImageSize.SQUARE, description='The size of the output image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBananaEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class NanoBananaPro(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Nano Banana Pro model (Gemini 3.0) via Kie.ai.

        kie, nano-banana-pro, google, gemini, image generation, ai, text-to-image, 4k, high-fidelity
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBananaPro.AspectRatio
    Resolution: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBananaPro.Resolution

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    image_input: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=[], description='Optional image inputs for multimodal generation.')
    aspect_ratio: nodetool.nodes.kie.image.NanoBananaPro.AspectRatio = Field(default=nodetool.nodes.kie.image.NanoBananaPro.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    resolution: nodetool.nodes.kie.image.NanoBananaPro.Resolution = Field(default=nodetool.nodes.kie.image.NanoBananaPro.Resolution.RES_2K, description='Output image resolution.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBananaPro

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class QwenImageToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Transform images using Qwen's Image-to-Image model via Kie.ai.

        kie, qwen, alibaba, image transformation, ai, image-to-image

        Qwen's image-to-image model transforms images based on text prompts
        while preserving the overall structure and style.

        Use cases:
        - Transform images with text guidance
        - Apply artistic styles to photos
        - Create variations of existing images
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.QwenImageToImage.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing how to transform the image.')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The source image to transform.')
    aspect_ratio: nodetool.nodes.kie.image.QwenImageToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.QwenImageToImage.AspectRatio.SQUARE, description='The aspect ratio of the output image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.QwenImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class QwenTextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Qwen's Text-to-Image model via Kie.ai.

        kie, qwen, alibaba, image generation, ai, text-to-image

        Qwen's text-to-image model generates high-quality images from text descriptions.

        Use cases:
        - Generate images from text descriptions
        - Create artistic and realistic images
        - Generate illustrations and artwork
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.QwenTextToImage.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.QwenTextToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.QwenTextToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.QwenTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class RecraftCrispUpscale(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Upscale images using Recraft's Crisp Upscale model via Kie.ai.

        kie, recraft, crisp-upscale, upscale, ai
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to upscale.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.RecraftCrispUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class RecraftRemoveBackground(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Remove background from images using Recraft's model via Kie.ai.

        kie, recraft, remove-background, image processing, ai

        Use cases:
        - Automatically remove backgrounds from photos
        - Create transparent PNGs for design work
        - Isolate subjects in images
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to remove the background from.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.RecraftRemoveBackground

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Seedream45Edit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Edit images using ByteDance's Seedream 4.5 Edit model via Kie.ai.

        kie, seedream, bytedance, image editing, ai, image-to-image, 4k

        Seedream 4.5 Edit allows you to modify existing images while maintaining
        high quality and detail fidelity up to 4K resolution.

        Use cases:
        - Edit and enhance existing images
        - Apply style changes to photos
        - Modify specific regions of images
        - Improve image quality and resolution
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Seedream45Edit.AspectRatio
    Quality: typing.ClassVar[type] = nodetool.nodes.kie.image.Seedream45Edit.Quality

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing how to edit the image.')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The source image to edit.')
    aspect_ratio: nodetool.nodes.kie.image.Seedream45Edit.AspectRatio = Field(default=nodetool.nodes.kie.image.Seedream45Edit.AspectRatio.SQUARE, description='The aspect ratio of the output image.')
    quality: nodetool.nodes.kie.image.Seedream45Edit.Quality = Field(default=nodetool.nodes.kie.image.Seedream45Edit.Quality.BASIC, description='Basic outputs 2K images, while High outputs 4K images.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream45Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class Seedream45TextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using ByteDance's Seedream 4.5 Text-to-Image model via Kie.ai.

        kie, seedream, bytedance, image generation, ai, text-to-image, 4k

        Seedream 4.5 generates high-quality visuals up to 4K resolution with
        improved detail fidelity, multi-image blending, and sharp text/face rendering.

        Use cases:
        - Generate creative and artistic images from text
        - Create diverse visual content up to 4K
        - Generate illustrations with unique styles
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio
    Quality: typing.ClassVar[type] = nodetool.nodes.kie.image.Seedream45TextToImage.Quality

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio = Field(default=nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')
    quality: nodetool.nodes.kie.image.Seedream45TextToImage.Quality = Field(default=nodetool.nodes.kie.image.Seedream45TextToImage.Quality.BASIC, description='Basic outputs 2K images, while High outputs 4K images.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream45TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class TopazImageUpscale(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Upscale and enhance images using Topaz Labs AI via Kie.ai.

        kie, topaz, upscale, enhance, image, ai, super-resolution

        Topaz Image Upscale uses advanced AI models to enlarge images
        while preserving and enhancing detail.

        Use cases:
        - Upscale low-resolution images
        - Enhance image quality and detail
        - Enlarge images for print or display
    """

    UpscaleFactor: typing.ClassVar[type] = nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to upscale.')
    upscale_factor: nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor = Field(default=nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor.X2, description='The upscaling factor (2x or 4x).')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.TopazImageUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode

class ZImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Alibaba's Z-Image Turbo model via Kie.ai.

        kie, z-image, zimage, alibaba, image generation, ai, text-to-image, photorealistic

        Z-Image Turbo produces realistic, detail-rich images with very low latency.
        It supports bilingual text (English/Chinese) in images with sharp text rendering.

        Use cases:
        - Generate high-quality photorealistic images quickly
        - Create images with embedded text (English/Chinese)
        - Generate detailed illustrations with low latency
        - Product visualizations
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.ZImage.AspectRatio

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt describing the image to generate.')
    aspect_ratio: nodetool.nodes.kie.image.ZImage.AspectRatio = Field(default=nodetool.nodes.kie.image.ZImage.AspectRatio.SQUARE, description='The aspect ratio of the generated image.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.ZImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


