# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Flux2FlexImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using Black Forest Labs' Flux 2 Flex Image-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-flex, black-forest-labs, image generation, ai, image-to-image

        Use cases:
        - Transform existing images with text prompts
        - Apply artistic styles to photos
        - Create variations of existing images
        - Enhance and modify images
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to transform the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to transform.",
    )
    aspect_ratio: nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Flux2FlexImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    resolution: nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution = Field(
        default=nodetool.nodes.kie.image.Flux2FlexImageToImage.Resolution.RES_1K,
        description="Output image resolution.",
    )
    steps: int | OutputHandle[int] = connect_field(
        default=25,
        description="Number of inference steps. Higher values may produce better quality but take longer.",
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=7.5,
        description="Guidance scale for the generation. Higher values adhere more closely to the prompt.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2FlexImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Flux2FlexTextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using Black Forest Labs' Flux 2 Flex Text-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-flex, black-forest-labs, image generation, ai, text-to-image

        Use cases:
        - Generate high-quality images from text with flexible parameters
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Flux2FlexTextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    resolution: nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution = Field(
        default=nodetool.nodes.kie.image.Flux2FlexTextToImage.Resolution.RES_1K,
        description="Output image resolution.",
    )
    steps: int | OutputHandle[int] = connect_field(
        default=25,
        description="Number of inference steps. Higher values may produce better quality but take longer.",
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=7.5,
        description="Guidance scale for the generation. Higher values adhere more closely to the prompt.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2FlexTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Flux2ProImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using Black Forest Labs' Flux 2 Pro Image-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-pro, black-forest-labs, image generation, ai, image-to-image

        Use cases:
        - Transform existing images with text prompts
        - Apply artistic styles to photos
        - Create variations of existing images
        - Enhance and modify images
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to transform the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to transform.",
    )
    aspect_ratio: nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Flux2ProImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    resolution: nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution = Field(
        default=nodetool.nodes.kie.image.Flux2ProImageToImage.Resolution.RES_1K,
        description="Output image resolution.",
    )
    steps: int | OutputHandle[int] = connect_field(
        default=25,
        description="Number of inference steps. Higher values may produce better quality but take longer.",
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=7.5,
        description="Guidance scale for the generation. Higher values adhere more closely to the prompt.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2ProImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Flux2ProTextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using Black Forest Labs' Flux 2 Pro Text-to-Image model via Kie.ai.

        kie, flux, flux-2, flux-pro, black-forest-labs, image generation, ai, text-to-image

        Use cases:
        - Generate high-quality artistic images from text
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Flux2ProTextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    resolution: nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution = Field(
        default=nodetool.nodes.kie.image.Flux2ProTextToImage.Resolution.RES_1K,
        description="Output image resolution.",
    )
    steps: int | OutputHandle[int] = connect_field(
        default=25,
        description="Number of inference steps. Higher values may produce better quality but take longer.",
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=7.5,
        description="Guidance scale for the generation. Higher values adhere more closely to the prompt.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Flux2ProTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class FluxKontext(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Black Forest Labs' Flux Kontext model via Kie.ai.

        kie, flux, flux-kontext, black-forest-labs, image generation, ai, text-to-image, editing

        Flux Kontext supports Pro (speed-optimized) and Max (quality-focused) variants
        with features like multiple aspect ratios, safety controls, and async processing.

        Use cases:
        - Generate high-quality artistic images
        - Advanced image editing and generation
        - Create professional visual content
        - Generate images with fine detail and artistic style
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.FluxKontext.AspectRatio
    )
    Mode: typing.ClassVar[type] = nodetool.nodes.kie.image.FluxKontext.Mode

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.FluxKontext.AspectRatio = Field(
        default=nodetool.nodes.kie.image.FluxKontext.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    mode: nodetool.nodes.kie.image.FluxKontext.Mode = Field(
        default=nodetool.nodes.kie.image.FluxKontext.Mode.PRO,
        description="Generation mode: 'pro' for speed, 'max' for quality.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.FluxKontext

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GPTImage15ImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Edit images using OpenAI's GPT Image 1.5 model via Kie.ai.

        kie, openai, gpt-image-1.5, image editing, ai, image-to-image

        GPT Image 1.5 enables precise image editing with strong instruction following
        and improved text rendering capabilities.

        Use cases:
        - Edit and transform existing images
        - Apply specific modifications with precise control
        - Add or modify text in images accurately
        - Create variations with high fidelity
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage15ImageToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage15ImageToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to edit the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to edit.",
    )
    aspect_ratio: nodetool.nodes.kie.image.GPTImage15ImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.GPTImage15ImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the output image.",
    )
    quality: nodetool.nodes.kie.image.GPTImage15ImageToImage.Quality = Field(
        default=nodetool.nodes.kie.image.GPTImage15ImageToImage.Quality.AUTO,
        description="Image quality setting.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GPTImage15ImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GPTImage15TextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using OpenAI's GPT Image 1.5 model via Kie.ai.

        kie, openai, gpt-image-1.5, image generation, ai, text-to-image

        GPT Image 1.5 is OpenAI's flagship image generation model for high-quality
        image creation and precise image editing, with strong instruction following
        and improved text rendering.

        Use cases:
        - Generate high-quality images from text descriptions
        - Create images with excellent text rendering
        - Generate professional marketing and design materials
        - Produce creative visuals with precise control
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage15TextToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage15TextToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.GPTImage15TextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.GPTImage15TextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    quality: nodetool.nodes.kie.image.GPTImage15TextToImage.Quality = Field(
        default=nodetool.nodes.kie.image.GPTImage15TextToImage.Quality.AUTO,
        description="Image quality setting.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GPTImage15TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GPTImage4oImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Edit images using OpenAI's GPT-4o Image model via Kie.ai.

        kie, openai, gpt-4o, 4o-image, image editing, ai, image-to-image

        The GPT-Image-1 model (ChatGPT 4o Image) enables precise image editing
        with strong instruction following and accurate text rendering.

        Use cases:
        - Edit and transform existing images
        - Apply specific modifications to images
        - Add or modify text in images
        - Create variations of existing visuals
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage4oImageToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage4oImageToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to edit the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to edit.",
    )
    aspect_ratio: nodetool.nodes.kie.image.GPTImage4oImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.GPTImage4oImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the output image.",
    )
    quality: nodetool.nodes.kie.image.GPTImage4oImageToImage.Quality = Field(
        default=nodetool.nodes.kie.image.GPTImage4oImageToImage.Quality.AUTO,
        description="Image quality setting.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GPTImage4oImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GPTImage4oTextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using OpenAI's GPT-4o Image model via Kie.ai.

        kie, openai, gpt-4o, 4o-image, image generation, ai, text-to-image

        The GPT-Image-1 model (ChatGPT 4o Image) understands both text and visual
        context, allowing precise image creation with accurate text rendering
        and consistent styles.

        Use cases:
        - Generate high-quality images from text descriptions
        - Create images with precise text rendering
        - Generate design and marketing materials
        - Produce creative visuals with strong instruction following
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage4oTextToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GPTImage4oTextToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.GPTImage4oTextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.GPTImage4oTextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    quality: nodetool.nodes.kie.image.GPTImage4oTextToImage.Quality = Field(
        default=nodetool.nodes.kie.image.GPTImage4oTextToImage.Quality.AUTO,
        description="Image quality setting.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GPTImage4oTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GrokImagineTextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using xAI's Grok Imagine Text-to-Image model via Kie.ai.

        kie, grok, xai, image generation, ai, text-to-image, multimodal

        Grok Imagine is a multimodal generative model that can generate images
        from text prompts.

        Use cases:
        - Generate images from text descriptions
        - Create visual content with AI
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.GrokImagineTextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GrokImagineTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class GrokImagineUpscale(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Upscale images using xAI's Grok Imagine Upscale model via Kie.ai.

        kie, grok, xai, upscale, enhance, image, ai, super-resolution

        Grok Imagine Upscale enhances and upscales images to higher resolutions
        while maintaining quality and detail.

        Constraints:
        - Only images generated by Kie AI models (via Grok Imagine) are supported for upscaling.
    """

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to upscale. Must be an image previously generated by a Kie.ai node.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.GrokImagineUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class IdeogramCharacterRemix(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Remix characters in images using Ideogram via Kie.ai.

        kie, ideogram, character-remix, image generation, ai, remix

        Ideogram Character Remix allows you to remix images while maintaining character consistency
        using reference images and text prompts.
    """

    RenderingSpeed: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed
    )
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramCharacterRemix.Style
    ImageSize: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="Text description for remixing."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Base image to remix.",
    )
    reference_images: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = (
        connect_field(
            default=[], description="Reference images for character guidance."
        )
    )
    rendering_speed: nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed = (
        Field(
            default=nodetool.nodes.kie.image.IdeogramCharacterRemix.RenderingSpeed.BALANCED,
            description="Rendering speed preference.",
        )
    )
    style: nodetool.nodes.kie.image.IdeogramCharacterRemix.Style = Field(
        default=nodetool.nodes.kie.image.IdeogramCharacterRemix.Style.AUTO,
        description="Generation style.",
    )
    expand_prompt: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to expand/augment the prompt."
    )
    image_size: nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize = Field(
        default=nodetool.nodes.kie.image.IdeogramCharacterRemix.ImageSize.SQUARE_HD,
        description="The size of the output image.",
    )
    strength: float | OutputHandle[float] = connect_field(
        default=0.8, description="How strongly to apply the remix (0.0 to 1.0)."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Undesired elements to exclude from the image."
    )
    additional_images: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = (
        connect_field(default=[], description="Additional image inputs.")
    )
    reference_mask_urls: str | OutputHandle[str] = connect_field(
        default="", description="URL(s) to masks for references (comma-separated)."
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramCharacterRemix

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class IdeogramV3ImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Edit images using Ideogram V3 model via Kie.ai.

        kie, ideogram, v3, image editing, ai, image-to-image

        Ideogram V3 offers image editing capabilities with improved consistency
        and creative control.

        Use cases:
        - Edit and transform existing images
        - Apply style changes while maintaining structure
        - Create variations of existing images
    """

    RenderingSpeed: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramV3ImageToImage.RenderingSpeed
    )
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3ImageToImage.Style

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to transform the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to transform.",
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Elements to avoid in the output."
    )
    rendering_speed: nodetool.nodes.kie.image.IdeogramV3ImageToImage.RenderingSpeed = (
        Field(
            default=nodetool.nodes.kie.image.IdeogramV3ImageToImage.RenderingSpeed.BALANCED,
            description="Rendering speed preference.",
        )
    )
    style: nodetool.nodes.kie.image.IdeogramV3ImageToImage.Style = Field(
        default=nodetool.nodes.kie.image.IdeogramV3ImageToImage.Style.AUTO,
        description="Generation style.",
    )
    image_weight: float | OutputHandle[float] = connect_field(
        default=0.5, description="How much to preserve from the original image (0-1)."
    )
    expand_prompt: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to expand/augment the prompt."
    )
    seed: int | OutputHandle[int] = connect_field(
        default=-1,
        description="Random seed for reproducible results. Use -1 for random.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramV3ImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class IdeogramV3Reframe(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Reframe images using Ideogram v3 via Kie.ai.

        kie, ideogram, v3-reframe, image processing, ai, reframe

        Use cases:
        - Reframe and rescale existing images
        - Change aspect ratio of images while maintaining quality
    """

    ImageSize: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize
    )
    RenderingSpeed: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed
    )
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3Reframe.Style

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL of the image to reframe.",
    )
    image_size: nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize = Field(
        default=nodetool.nodes.kie.image.IdeogramV3Reframe.ImageSize.SQUARE_HD,
        description="Output resolution preset.",
    )
    rendering_speed: nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed = Field(
        default=nodetool.nodes.kie.image.IdeogramV3Reframe.RenderingSpeed.BALANCED,
        description="Rendering speed preference.",
    )
    style: nodetool.nodes.kie.image.IdeogramV3Reframe.Style = Field(
        default=nodetool.nodes.kie.image.IdeogramV3Reframe.Style.AUTO,
        description="Generation style.",
    )
    seed: int | OutputHandle[int] = connect_field(default=0, description="RNG seed.")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramV3Reframe

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class IdeogramV3TextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using Ideogram V3 model via Kie.ai.

        kie, ideogram, v3, image generation, ai, text-to-image

        Ideogram V3 is the latest generation of Ideogram's image generation model,
        offering text-to-image with improved consistency and creative control.

        Use cases:
        - Generate creative images from text descriptions
        - Create images with excellent text rendering
        - Produce artistic and design content
    """

    RenderingSpeed: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed
    )
    Style: typing.ClassVar[type] = nodetool.nodes.kie.image.IdeogramV3TextToImage.Style
    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.IdeogramV3TextToImage.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Elements to avoid in the generated image."
    )
    rendering_speed: nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed = (
        Field(
            default=nodetool.nodes.kie.image.IdeogramV3TextToImage.RenderingSpeed.BALANCED,
            description="Rendering speed preference.",
        )
    )
    style: nodetool.nodes.kie.image.IdeogramV3TextToImage.Style = Field(
        default=nodetool.nodes.kie.image.IdeogramV3TextToImage.Style.AUTO,
        description="Generation style.",
    )
    aspect_ratio: nodetool.nodes.kie.image.IdeogramV3TextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.IdeogramV3TextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    expand_prompt: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to expand/augment the prompt."
    )
    seed: int | OutputHandle[int] = connect_field(
        default=-1,
        description="Random seed for reproducible results. Use -1 for random.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.IdeogramV3TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Imagen4(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 model via Kie.ai.

        kie, google, imagen, imagen4, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.Imagen4.AspectRatio

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Undesired elements to exclude."
    )
    aspect_ratio: nodetool.nodes.kie.image.Imagen4.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Imagen4.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    seed: int | OutputHandle[int] = connect_field(default=0, description="RNG seed.")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Imagen4Fast(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 Fast model via Kie.ai.

        kie, google, imagen, imagen4, fast, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Imagen4Fast.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Undesired elements to exclude."
    )
    aspect_ratio: nodetool.nodes.kie.image.Imagen4Fast.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Imagen4Fast.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4Fast

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Imagen4Ultra(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Imagen 4 Ultra model via Kie.ai.

        kie, google, imagen, imagen4, ultra, image generation, ai
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Undesired elements to exclude."
    )
    aspect_ratio: nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Imagen4Ultra.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    seed: int | OutputHandle[int] = connect_field(default=0, description="RNG seed.")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Imagen4Ultra

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class NanoBanana(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Nano Banana model (Gemini 2.5) via Kie.ai.

        kie, nano-banana, google, gemini, image generation, ai, text-to-image, fast
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBanana.ImageSize

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    image_size: nodetool.nodes.kie.image.NanoBanana.ImageSize = Field(
        default=nodetool.nodes.kie.image.NanoBanana.ImageSize.SQUARE,
        description="The size of the output image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBanana

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class NanoBananaEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Edit images using Google's Nano Banana model via Kie.ai.

        kie, google, nano-banana, nano-banana-edit, image editing, ai
    """

    ImageSize: typing.ClassVar[type] = nodetool.nodes.kie.image.NanoBananaEdit.ImageSize

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="Text description of the changes to make."
    )
    image_input: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = (
        connect_field(default=[], description="Images to edit.")
    )
    image_size: nodetool.nodes.kie.image.NanoBananaEdit.ImageSize = Field(
        default=nodetool.nodes.kie.image.NanoBananaEdit.ImageSize.SQUARE,
        description="The size of the output image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBananaEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class NanoBananaPro(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Google's Nano Banana Pro model (Gemini 3.0) via Kie.ai.

        kie, nano-banana-pro, google, gemini, image generation, ai, text-to-image, 4k, high-fidelity
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.NanoBananaPro.AspectRatio
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.NanoBananaPro.Resolution
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    image_input: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = (
        connect_field(
            default=[], description="Optional image inputs for multimodal generation."
        )
    )
    aspect_ratio: nodetool.nodes.kie.image.NanoBananaPro.AspectRatio = Field(
        default=nodetool.nodes.kie.image.NanoBananaPro.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    resolution: nodetool.nodes.kie.image.NanoBananaPro.Resolution = Field(
        default=nodetool.nodes.kie.image.NanoBananaPro.Resolution.RES_2K,
        description="Output image resolution.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.NanoBananaPro

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class QwenImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Transform images using Qwen's Image-to-Image model via Kie.ai.

        kie, qwen, alibaba, image transformation, ai, image-to-image

        Qwen's image-to-image model transforms images based on text prompts
        while preserving the overall structure and style.

        Use cases:
        - Transform images with text guidance
        - Apply artistic styles to photos
        - Create variations of existing images
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.QwenImageToImage.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to transform the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to transform.",
    )
    aspect_ratio: nodetool.nodes.kie.image.QwenImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.QwenImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the output image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.QwenImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class QwenTextToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Qwen's Text-to-Image model via Kie.ai.

        kie, qwen, alibaba, image generation, ai, text-to-image

        Qwen's text-to-image model generates high-quality images from text descriptions.

        Use cases:
        - Generate images from text descriptions
        - Create artistic and realistic images
        - Generate illustrations and artwork
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.QwenTextToImage.AspectRatio
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.QwenTextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.QwenTextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.QwenTextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class RecraftCrispUpscale(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Upscale images using Recraft's Crisp Upscale model via Kie.ai.

        kie, recraft, crisp-upscale, upscale, ai
    """

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to upscale.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.RecraftCrispUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class RecraftRemoveBackground(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Remove background from images using Recraft's model via Kie.ai.

        kie, recraft, remove-background, image processing, ai

        Use cases:
        - Automatically remove backgrounds from photos
        - Create transparent PNGs for design work
        - Isolate subjects in images
    """

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to remove the background from.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.RecraftRemoveBackground

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Seedream40ImageToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Edit images using ByteDance's Seedream 4.0 model via Kie.ai.

        kie, seedream, bytedance, seedream-4, image editing, ai, image-to-image

        Seedream 4.0 offers image-to-image capabilities with batch consistency
        and professional-quality outputs.

        Use cases:
        - Edit and transform existing images
        - Apply style changes to photos
        - Create variations of existing images
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream40ImageToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream40ImageToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to transform the image."
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The source image to transform.",
    )
    aspect_ratio: nodetool.nodes.kie.image.Seedream40ImageToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Seedream40ImageToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the output image.",
    )
    quality: nodetool.nodes.kie.image.Seedream40ImageToImage.Quality = Field(
        default=nodetool.nodes.kie.image.Seedream40ImageToImage.Quality.BASIC,
        description="Basic outputs 2K images, while High outputs 4K images.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream40ImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Seedream40TextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using ByteDance's Seedream 4.0 model via Kie.ai.

        kie, seedream, bytedance, seedream-4, image generation, ai, text-to-image

        Seedream 4.0 is ByteDance's image generation model that combines text-to-image
        with batch consistency, high speed, and professional-quality outputs.

        Use cases:
        - Generate creative and artistic images from text
        - Create professional visual content
        - Produce consistent batch images
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream40TextToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream40TextToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.Seedream40TextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Seedream40TextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    quality: nodetool.nodes.kie.image.Seedream40TextToImage.Quality = Field(
        default=nodetool.nodes.kie.image.Seedream40TextToImage.Quality.BASIC,
        description="Basic outputs 2K images, while High outputs 4K images.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream40TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Seedream45Edit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Edit images using ByteDance's Seedream 4.5 Edit model via Kie.ai.

        kie, seedream, bytedance, image editing, ai, image-to-image, 4k

        Seedream 4.5 Edit allows you to modify existing images while maintaining
        high quality and detail fidelity up to 4K resolution.

        Use cases:
        - Edit and enhance existing images
        - Apply style changes to photos
        - Modify specific regions of images
        - Improve image quality and resolution
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream45Edit.AspectRatio
    )
    Quality: typing.ClassVar[type] = nodetool.nodes.kie.image.Seedream45Edit.Quality

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing how to edit the image."
    )
    image_input: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = (
        connect_field(default=[], description="The source images to edit.")
    )
    aspect_ratio: nodetool.nodes.kie.image.Seedream45Edit.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Seedream45Edit.AspectRatio.SQUARE,
        description="The aspect ratio of the output image.",
    )
    quality: nodetool.nodes.kie.image.Seedream45Edit.Quality = Field(
        default=nodetool.nodes.kie.image.Seedream45Edit.Quality.BASIC,
        description="Basic outputs 2K images, while High outputs 4K images.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream45Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class Seedream45TextToImage(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Generate images using ByteDance's Seedream 4.5 Text-to-Image model via Kie.ai.

        kie, seedream, bytedance, image generation, ai, text-to-image, 4k

        Seedream 4.5 generates high-quality visuals up to 4K resolution with
        improved detail fidelity, multi-image blending, and sharp text/face rendering.

        Use cases:
        - Generate creative and artistic images from text
        - Create diverse visual content up to 4K
        - Generate illustrations with unique styles
    """

    AspectRatio: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio
    )
    Quality: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.Seedream45TextToImage.Quality
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.Seedream45TextToImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )
    quality: nodetool.nodes.kie.image.Seedream45TextToImage.Quality = Field(
        default=nodetool.nodes.kie.image.Seedream45TextToImage.Quality.BASIC,
        description="Basic outputs 2K images, while High outputs 4K images.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.Seedream45TextToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class TopazImageUpscale(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Upscale and enhance images using Topaz Labs AI via Kie.ai.

        kie, topaz, upscale, enhance, image, ai, super-resolution

        Topaz Image Upscale uses advanced AI models to enlarge images
        while preserving and enhancing detail.

        Use cases:
        - Upscale low-resolution images
        - Enhance image quality and detail
        - Enlarge images for print or display
    """

    UpscaleFactor: typing.ClassVar[type] = (
        nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor
    )

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The image to upscale.",
    )
    upscale_factor: nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor = Field(
        default=nodetool.nodes.kie.image.TopazImageUpscale.UpscaleFactor.X2,
        description="The upscaling factor (2x or 4x).",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.TopazImageUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.kie.image
from nodetool.workflows.base_node import BaseNode


class ZImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Generate images using Alibaba's Z-Image Turbo model via Kie.ai.

        kie, z-image, zimage, alibaba, image generation, ai, text-to-image, photorealistic

        Z-Image Turbo produces realistic, detail-rich images with very low latency.
        It supports bilingual text (English/Chinese) in images with sharp text rendering.

        Use cases:
        - Generate high-quality photorealistic images quickly
        - Create images with embedded text (English/Chinese)
        - Generate detailed illustrations with low latency
        - Product visualizations
    """

    AspectRatio: typing.ClassVar[type] = nodetool.nodes.kie.image.ZImage.AspectRatio

    timeout_seconds: int | OutputHandle[int] = connect_field(
        default=0, description="Timeout in seconds for API calls (0 = use default)"
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The text prompt describing the image to generate."
    )
    aspect_ratio: nodetool.nodes.kie.image.ZImage.AspectRatio = Field(
        default=nodetool.nodes.kie.image.ZImage.AspectRatio.SQUARE,
        description="The aspect ratio of the generated image.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.kie.image.ZImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
