# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class AutomaticSpeechRecognition(
    GraphNode[nodetool.nodes.nodetool.text.AutomaticSpeechRecognition.OutputType]
):
    """
    Automatic speech recognition node.
    audio, speech, recognition
    """

    model: types.ASRModel | OutputHandle[types.ASRModel] = connect_field(
        default=types.ASRModel(
            type="asr_model",
            provider=nodetool.metadata.types.Provider.FalAI,
            id="openai/whisper-large-v3",
            name="",
        ),
        description=None,
    )
    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(type="audio", uri="", asset_id=None, data=None),
        description="The audio to transcribe",
    )

    @property
    def out(self) -> "AutomaticSpeechRecognitionOutputs":
        return AutomaticSpeechRecognitionOutputs(self)

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.AutomaticSpeechRecognition"


class AutomaticSpeechRecognitionOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["text"])


AutomaticSpeechRecognition.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Chunk(GraphNode[list[str]]):
    """
    Splits text into chunks of specified word length.
    text, chunk, split

    Use cases:
    - Preparing text for processing by models with input length limits
    - Creating manageable text segments for parallel processing
    - Generating summaries of text sections
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    length: int | OutputHandle[int] = connect_field(default=100, description=None)
    overlap: int | OutputHandle[int] = connect_field(default=0, description=None)
    separator: str | OutputHandle[str] | None = connect_field(
        default=None, description=None
    )

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Chunk"


Chunk.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Collect(GraphNode[nodetool.nodes.nodetool.text.Collect.OutputType]):
    """
    Collects a stream of text inputs into a single string.
    text, collect, list, stream
    """

    input_item: str | OutputHandle[str] = connect_field(default="", description=None)
    separator: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def out(self) -> "CollectOutputs":
        return CollectOutputs(self)

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Collect"


class CollectOutputs(OutputsProxy):
    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["output"])


Collect.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Concat(GraphNode[str]):
    """
    Concatenates two text inputs into a single output.
    text, concatenation, combine, +

    Use cases:
    - Joining outputs from multiple text processing nodes
    - Combining parts of sentences or paragraphs
    - Merging text data from different sources
    """

    a: str | OutputHandle[str] = connect_field(default="", description=None)
    b: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Concat"


Concat.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Contains(GraphNode[bool]):
    """
    Checks if text contains a specified substring.
    text, check, contains, compare, validate, substring, string

    Use cases:
    - Searching for keywords in text
    - Filtering content based on presence of terms
    - Validating text content
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    substring: str | OutputHandle[str] = connect_field(default="", description=None)
    case_sensitive: bool | OutputHandle[bool] = connect_field(
        default=True, description=None
    )

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Contains"


Contains.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
import nodetool.nodes.nodetool.text


class CountTokens(GraphNode[int]):
    """
    Counts the number of tokens in text using tiktoken.
    text, tokens, count, encoding

    Use cases:
    - Checking text length for LLM input limits
    - Estimating API costs
    - Managing token budgets in text processing
    """

    TiktokenEncoding: typing.ClassVar[type] = (
        nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding
    )
    text: str | OutputHandle[str] = connect_field(default="", description=None)
    encoding: nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding = Field(
        default=nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding.CL100K_BASE,
        description="The tiktoken encoding to use for token counting",
    )

    @property
    def output(self) -> OutputHandle[int]:
        return typing.cast(OutputHandle[int], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.CountTokens"


CountTokens.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class EndsWith(GraphNode[bool]):
    """
    Checks if text ends with a specified suffix.
    text, check, suffix, compare, validate, substring, string

    Use cases:
    - Validating file extensions
    - Checking string endings
    - Filtering text based on ending content
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    suffix: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.EndsWith"


EndsWith.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Extract(GraphNode[str]):
    """
    Extracts a substring from input text.
    text, extract, substring

    Use cases:
    - Extracting specific portions of text for analysis
    - Trimming unwanted parts from text data
    - Focusing on relevant sections of longer documents
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    start: int | OutputHandle[int] = connect_field(default=0, description=None)
    end: int | OutputHandle[int] = connect_field(default=0, description=None)

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Extract"


Extract.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class ExtractJSON(GraphNode[Any]):
    """
    Extracts data from JSON using JSONPath expressions.
    json, extract, jsonpath

    Use cases:
    - Retrieving specific fields from complex JSON structures
    - Filtering and transforming JSON data for analysis
    - Extracting nested data from API responses or configurations
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    json_path: str | OutputHandle[str] = connect_field(default="$.*", description=None)
    find_all: bool | OutputHandle[bool] = connect_field(default=False, description=None)

    @property
    def output(self) -> OutputHandle[Any]:
        return typing.cast(OutputHandle[Any], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.ExtractJSON"


ExtractJSON.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class ExtractRegex(GraphNode[list[str]]):
    """
    Extracts substrings matching regex groups from text.
    text, regex, extract

    Use cases:
    - Extracting structured data (e.g., dates, emails) from unstructured text
    - Parsing specific patterns in log files or documents
    - Isolating relevant information from complex text formats
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    regex: str | OutputHandle[str] = connect_field(default="", description=None)
    dotall: bool | OutputHandle[bool] = connect_field(default=False, description=None)
    ignorecase: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )
    multiline: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.ExtractRegex"


ExtractRegex.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class FindAllRegex(GraphNode[list[str]]):
    """
    Finds all regex matches in text as separate substrings.
    text, regex, find

    Use cases:
    - Identifying all occurrences of a pattern in text
    - Extracting multiple instances of structured data
    - Analyzing frequency and distribution of specific text patterns
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    regex: str | OutputHandle[str] = connect_field(default="", description=None)
    dotall: bool | OutputHandle[bool] = connect_field(default=False, description=None)
    ignorecase: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )
    multiline: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.FindAllRegex"


FindAllRegex.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class FormatText(GraphNode[str]):
    """
    Replaces placeholders in a string with dynamic inputs using Jinja2 templating.
    text, template, formatting

    This node is dynamic and can be used to format text with dynamic properties.

    Use cases:
    - Generating personalized messages with dynamic content
    - Creating parameterized queries or commands
    - Formatting and filtering text output based on variable inputs

    Examples:
    - text: "Hello, {{ name }}!"
    - text: "Title: {{ title|truncate(20) }}"
    - text: "Name: {{ name|upper }}"

    Available filters:
    - truncate(length): Truncates text to given length
    - upper: Converts text to uppercase
    - lower: Converts text to lowercase
    - title: Converts text to title case
    - trim: Removes whitespace from start/end
    - replace(old, new): Replaces substring
    - default(value): Sets default if value is undefined
    - first: Gets first character/item
    - last: Gets last character/item
    - length: Gets length of string/list
    - sort: Sorts list
    - join(delimiter): Joins list with delimiter
    """

    template: str | OutputHandle[str] = connect_field(
        default="",
        description='\n    Examples:\n    - text: "Hello, {{ name }}!"\n    - text: "Title: {{ title|truncate(20) }}"\n    - text: "Name: {{ name|upper }}" \n\n    Available filters:\n    - truncate(length): Truncates text to given length\n    - upper: Converts text to uppercase\n    - lower: Converts text to lowercase\n    - title: Converts text to title case\n    - trim: Removes whitespace from start/end\n    - replace(old, new): Replaces substring\n    - default(value): Sets default if value is undefined\n    - first: Gets first character/item\n    - last: Gets last character/item\n    - length: Gets length of string/list\n    - sort: Sorts list\n    - join(delimiter): Joins list with delimiter\n',
    )

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.FormatText"


FormatText.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class HasLength(GraphNode[bool]):
    """
    Checks if text length meets specified conditions.
    text, check, length, compare, validate, whitespace, string

    Use cases:
    - Validating input length requirements
    - Filtering text by length
    - Checking content size constraints
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    min_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    max_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    exact_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.HasLength"


HasLength.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class HtmlToText(GraphNode[str]):
    """
    Converts HTML content to plain text using html2text.
    html, convert, text, parse, extract

    Use cases:
    - Converting HTML documents to readable plain text
    - Extracting text content from web pages
    - Cleaning HTML markup from text data
    - Processing HTML emails or documents
    """

    html: str | OutputHandle[str] = connect_field(
        default="", description="HTML content to convert"
    )
    base_url: str | OutputHandle[str] = connect_field(
        default="", description="Base URL for resolving relative links"
    )
    body_width: int | OutputHandle[int] = connect_field(
        default=1000, description="Width for text wrapping"
    )
    ignore_images: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to ignore image tags"
    )
    ignore_mailto_links: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to ignore mailto links"
    )

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.HtmlToText"


HtmlToText.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class IsEmpty(GraphNode[bool]):
    """
    Checks if text is empty or contains only whitespace.
    text, check, empty, compare, validate, whitespace, string

    Use cases:
    - Validating required text fields
    - Filtering out empty content
    - Checking for meaningful input
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    trim_whitespace: bool | OutputHandle[bool] = connect_field(
        default=True, description=None
    )

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.IsEmpty"


IsEmpty.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Join(GraphNode[str]):
    """
    Joins a list of strings into a single string using a specified separator.
    text, join, combine, +, add, concatenate

    Use cases:
    - Combining multiple text elements with a consistent delimiter
    - Creating comma-separated lists from individual items
    - Assembling formatted text from array elements
    """

    strings: list[str] | OutputHandle[list[str]] = connect_field(
        default=[], description=None
    )
    separator: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Join"


Join.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class LoadTextAssets(GraphNode[nodetool.nodes.nodetool.text.LoadTextAssets.OutputType]):
    """
    Load text files from an asset folder.
    load, text, file, import

    Use cases:
    - Loading multiple text files for batch processing
    - Importing text content from a directory
    - Processing collections of text documents
    """

    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(
        default=types.FolderRef(type="folder", uri="", asset_id=None, data=None),
        description="The asset folder to load the text files from.",
    )

    @property
    def out(self) -> "LoadTextAssetsOutputs":
        return LoadTextAssetsOutputs(self)

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.LoadTextAssets"


class LoadTextAssetsOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[types.TextRef]:
        return typing.cast(OutputHandle[types.TextRef], self["text"])

    @property
    def name(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["name"])


LoadTextAssets.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class ParseJSON(GraphNode[Any]):
    """
    Parses a JSON string into a Python object.
    json, parse, convert

    Use cases:
    - Converting JSON API responses for further processing
    - Preparing structured data for analysis or storage
    - Extracting configuration or settings from JSON files
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[Any]:
        return typing.cast(OutputHandle[Any], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.ParseJSON"


ParseJSON.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class RegexMatch(GraphNode[list[str]]):
    """
    Find all matches of a regex pattern in text.
    regex, search, pattern, match

    Use cases:
    - Extract specific patterns from text
    - Validate text against patterns
    - Find all occurrences of a pattern
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to search in"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )
    group: int | OutputHandle[int] | None = connect_field(
        default=None, description="Capture group to extract (0 for full match)"
    )

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.RegexMatch"


RegexMatch.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class RegexReplace(GraphNode[str]):
    """
    Replace text matching a regex pattern.
    regex, replace, substitute

    Use cases:
    - Clean or standardize text
    - Remove unwanted patterns
    - Transform text formats
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to perform replacements on"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )
    replacement: str | OutputHandle[str] = connect_field(
        default="", description="Replacement text"
    )
    count: int | OutputHandle[int] = connect_field(
        default=0, description="Maximum replacements (0 for unlimited)"
    )

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.RegexReplace"


RegexReplace.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class RegexSplit(GraphNode[list[str]]):
    """
    Split text using a regex pattern as delimiter.
    regex, split, tokenize

    Use cases:
    - Parse structured text
    - Extract fields from formatted strings
    - Tokenize text
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to split"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern to split on"
    )
    maxsplit: int | OutputHandle[int] = connect_field(
        default=0, description="Maximum number of splits (0 for unlimited)"
    )

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.RegexSplit"


RegexSplit.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class RegexValidate(GraphNode[bool]):
    """
    Check if text matches a regex pattern.
    regex, validate, check

    Use cases:
    - Validate input formats (email, phone, etc)
    - Check text structure
    - Filter text based on patterns
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to validate"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.RegexValidate"


RegexValidate.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Replace(GraphNode[str]):
    """
    Replaces a substring in a text with another substring.
    text, replace, substitute

    Use cases:
    - Correcting or updating specific text patterns
    - Sanitizing or normalizing text data
    - Implementing simple text transformations
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    old: str | OutputHandle[str] = connect_field(default="", description=None)
    new: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Replace"


Replace.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class SaveText(GraphNode[types.TextRef]):
    """
    Saves input text to a file in the assets folder.
    text, save, file

    Use cases:
    - Persisting processed text results
    - Creating text files for downstream nodes or external use
    - Archiving text data within the workflow
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(
        default=types.FolderRef(type="folder", uri="", asset_id=None, data=None),
        description="Name of the output folder.",
    )
    name: str | OutputHandle[str] = connect_field(
        default="%Y-%m-%d-%H-%M-%S.txt",
        description="\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
    )

    @property
    def output(self) -> OutputHandle[types.TextRef]:
        return typing.cast(OutputHandle[types.TextRef], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.SaveText"


SaveText.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class SaveTextFile(GraphNode[types.TextRef]):
    """
    Saves input text to a file in the assets folder.
    text, save, file
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    folder: str | OutputHandle[str] = connect_field(
        default="", description="Path to the output folder."
    )
    name: str | OutputHandle[str] = connect_field(
        default="%Y-%m-%d-%H-%M-%S.txt",
        description="\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
    )

    @property
    def output(self) -> OutputHandle[types.TextRef]:
        return typing.cast(OutputHandle[types.TextRef], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.SaveTextFile"


SaveTextFile.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Slice(GraphNode[str]):
    """
    Slices text using Python's slice notation (start:stop:step).
    text, slice, substring

    Use cases:
    - Extracting specific portions of text with flexible indexing
    - Reversing text using negative step
    - Taking every nth character with step parameter

    Examples:
    - start=0, stop=5: first 5 characters
    - start=-5: last 5 characters
    - step=2: every second character
    - step=-1: reverse the text
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    start: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    stop: int | OutputHandle[int] | None = connect_field(default=None, description=None)
    step: int | OutputHandle[int] | None = connect_field(default=None, description=None)

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Slice"


Slice.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Split(GraphNode[list[str]]):
    """
    Separates text into a list of strings based on a specified delimiter.
    text, split, tokenize

    Use cases:
    - Parsing CSV or similar delimited data
    - Breaking down sentences into words or phrases
    - Extracting specific elements from structured text
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    delimiter: str | OutputHandle[str] = connect_field(default=",", description=None)

    @property
    def output(self) -> OutputHandle[list[str]]:
        return typing.cast(OutputHandle[list[str]], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Split"


Split.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class StartsWith(GraphNode[bool]):
    """
    Checks if text starts with a specified prefix.
    text, check, prefix, compare, validate, substring, string

    Use cases:
    - Validating string prefixes
    - Filtering text based on starting content
    - Checking file name patterns
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    prefix: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def output(self) -> OutputHandle[bool]:
        return typing.cast(OutputHandle[bool], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.StartsWith"


StartsWith.model_rebuild(force=True)


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text


class Template(GraphNode[str]):
    """
    Uses Jinja2 templating to format strings with variables and filters. This node is dynamic and can be used to format text with dynamic inputs.
    text, template, formatting, format, combine, concatenate, +, add, variable, replace, filter

    Use cases:
    - Generating personalized messages with dynamic content
    - Creating parameterized queries or commands
    - Formatting and filtering text output based on variable inputs

    Examples:
    - text: "Hello, {{ name }}!"
    - text: "Title: {{ title|truncate(20) }}"
    - text: "Name: {{ name|upper }}"

    Available filters:
    - truncate(length): Truncates text to given length
    - upper: Converts text to uppercase
    - lower: Converts text to lowercase
    - title: Converts text to title case
    - trim: Removes whitespace from start/end
    - replace(old, new): Replaces substring
    - default(value): Sets default if value is undefined
    - first: Gets first character/item
    - last: Gets last character/item
    - length: Gets length of string/list
    - sort: Sorts list
    - join(delimiter): Joins list with delimiter
    """

    string: str | OutputHandle[str] = connect_field(
        default="",
        description='\n    Examples:\n    - text: "Hello, {{ name }}!"\n    - text: "Title: {{ title|truncate(20) }}"\n    - text: "Name: {{ name|upper }}"\n\n    Available filters:\n    - truncate(length): Truncates text to given length\n    - upper: Converts text to uppercase\n    - lower: Converts text to lowercase\n    - title: Converts text to title case\n    - trim: Removes whitespace from start/end\n    - replace(old, new): Replaces substring\n    - default(value): Sets default if value is undefined\n    - first: Gets first character/item\n    - last: Gets last character/item\n    - length: Gets length of string/list\n    - sort: Sorts list\n    - join(delimiter): Joins list with delimiter\n',
    )
    values: Any | OutputHandle[Any] = connect_field(
        default={},
        description="\n        The values to replace in the string.\n        - If a string, it will be used as the format string.\n        - If a list, it will be used as the format arguments.\n        - If a dictionary, it will be used as the template variables.\n        - If an object, it will be converted to a dictionary using the object's __dict__ method.\n        ",
    )

    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self._single_output_handle())

    @classmethod
    def get_node_type(cls):
        return "nodetool.text.Template"


Template.model_rebuild(force=True)
