# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class AutomaticSpeechRecognition(
    GraphNode[nodetool.nodes.nodetool.text.AutomaticSpeechRecognition.OutputType]
):
    """
    Automatic speech recognition node.
    audio, speech, recognition
    """

    model: types.ASRModel | OutputHandle[types.ASRModel] = connect_field(
        default=types.ASRModel(
            type="asr_model",
            provider=nodetool.metadata.types.Provider.FalAI,
            id="openai/whisper-large-v3",
            name="",
        ),
        description=None,
    )
    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(type="audio", uri="", asset_id=None, data=None),
        description="The audio to transcribe",
    )

    @property
    def out(self) -> "AutomaticSpeechRecognitionOutputs":
        return AutomaticSpeechRecognitionOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.AutomaticSpeechRecognition

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class AutomaticSpeechRecognitionOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["text"])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Chunk(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Splits text into chunks of specified word length.
    text, chunk, split

    Use cases:
    - Preparing text for processing by models with input length limits
    - Creating manageable text segments for parallel processing
    - Generating summaries of text sections
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    length: int | OutputHandle[int] = connect_field(default=100, description=None)
    overlap: int | OutputHandle[int] = connect_field(default=0, description=None)
    separator: str | OutputHandle[str] | None = connect_field(
        default=None, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Chunk

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Collect(GraphNode[nodetool.nodes.nodetool.text.Collect.OutputType]):
    """
    Collects a stream of text inputs into a single string.
    text, collect, list, stream
    """

    input_item: str | OutputHandle[str] = connect_field(default="", description=None)
    separator: str | OutputHandle[str] = connect_field(default="", description=None)

    @property
    def out(self) -> "CollectOutputs":
        return CollectOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Collect

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class CollectOutputs(OutputsProxy):
    @property
    def output(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["output"])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Concat(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Concatenates two text inputs into a single output.
    text, concatenation, combine, +

    Use cases:
    - Joining outputs from multiple text processing nodes
    - Combining parts of sentences or paragraphs
    - Merging text data from different sources
    """

    a: str | OutputHandle[str] = connect_field(default="", description=None)
    b: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Concat

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Contains(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Checks if text contains a specified substring.
    text, check, contains, compare, validate, substring, string

    Use cases:
    - Searching for keywords in text
    - Filtering content based on presence of terms
    - Validating text content
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    substring: str | OutputHandle[str] = connect_field(default="", description=None)
    case_sensitive: bool | OutputHandle[bool] = connect_field(
        default=True, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Contains

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.nodetool.text


class CountTokens(SingleOutputGraphNode[int], GraphNode[int]):
    """
    Counts the number of tokens in text using tiktoken.
    text, tokens, count, encoding

    Use cases:
    - Checking text length for LLM input limits
    - Estimating API costs
    - Managing token budgets in text processing
    """

    TiktokenEncoding: typing.ClassVar[type] = (
        nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding
    )
    text: str | OutputHandle[str] = connect_field(default="", description=None)
    encoding: nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding = Field(
        default=nodetool.nodes.nodetool.text.CountTokens.TiktokenEncoding.CL100K_BASE,
        description="The tiktoken encoding to use for token counting",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.CountTokens

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class EndsWith(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Checks if text ends with a specified suffix.
    text, check, suffix, compare, validate, substring, string

    Use cases:
    - Validating file extensions
    - Checking string endings
    - Filtering text based on ending content
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    suffix: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.EndsWith

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Extract(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Extracts a substring from input text.
    text, extract, substring

    Use cases:
    - Extracting specific portions of text for analysis
    - Trimming unwanted parts from text data
    - Focusing on relevant sections of longer documents
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    start: int | OutputHandle[int] = connect_field(default=0, description=None)
    end: int | OutputHandle[int] = connect_field(default=0, description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Extract

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class ExtractJSON(SingleOutputGraphNode[Any], GraphNode[Any]):
    """
    Extracts data from JSON using JSONPath expressions.
    json, extract, jsonpath

    Use cases:
    - Retrieving specific fields from complex JSON structures
    - Filtering and transforming JSON data for analysis
    - Extracting nested data from API responses or configurations
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    json_path: str | OutputHandle[str] = connect_field(default="$.*", description=None)
    find_all: bool | OutputHandle[bool] = connect_field(default=False, description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.ExtractJSON

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class ExtractRegex(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Extracts substrings matching regex groups from text.
    text, regex, extract

    Use cases:
    - Extracting structured data (e.g., dates, emails) from unstructured text
    - Parsing specific patterns in log files or documents
    - Isolating relevant information from complex text formats
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    regex: str | OutputHandle[str] = connect_field(default="", description=None)
    dotall: bool | OutputHandle[bool] = connect_field(default=False, description=None)
    ignorecase: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )
    multiline: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.ExtractRegex

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class FindAllRegex(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Finds all regex matches in text as separate substrings.
    text, regex, find

    Use cases:
    - Identifying all occurrences of a pattern in text
    - Extracting multiple instances of structured data
    - Analyzing frequency and distribution of specific text patterns
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    regex: str | OutputHandle[str] = connect_field(default="", description=None)
    dotall: bool | OutputHandle[bool] = connect_field(default=False, description=None)
    ignorecase: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )
    multiline: bool | OutputHandle[bool] = connect_field(
        default=False, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.FindAllRegex

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class FormatText(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Replaces placeholders in a string with dynamic inputs using Jinja2 templating.
    text, template, formatting

    This node is dynamic and can be used to format text with dynamic properties.

    Use cases:
    - Generating personalized messages with dynamic content
    - Creating parameterized queries or commands
    - Formatting and filtering text output based on variable inputs

    Examples:
    - text: "Hello, {{ name }}!"
    - text: "Title: {{ title|truncate(20) }}"
    - text: "Name: {{ name|upper }}"

    Available filters:
    - truncate(length): Truncates text to given length
    - upper: Converts text to uppercase
    - lower: Converts text to lowercase
    - title: Converts text to title case
    - trim: Removes whitespace from start/end
    - replace(old, new): Replaces substring
    - default(value): Sets default if value is undefined
    - first: Gets first character/item
    - last: Gets last character/item
    - length: Gets length of string/list
    - sort: Sorts list
    - join(delimiter): Joins list with delimiter


    This node supports dynamic properties. Additional properties can be passed
    as keyword arguments during initialization and will be stored in the node's
    dynamic_properties dictionary.

    Example:
        node = FormatText(prop1=value1, prop2=value2)
    """

    template: str | OutputHandle[str] = connect_field(
        default="",
        description='\n    Examples:\n    - text: "Hello, {{ name }}!"\n    - text: "Title: {{ title|truncate(20) }}"\n    - text: "Name: {{ name|upper }}" \n\n    Available filters:\n    - truncate(length): Truncates text to given length\n    - upper: Converts text to uppercase\n    - lower: Converts text to lowercase\n    - title: Converts text to title case\n    - trim: Removes whitespace from start/end\n    - replace(old, new): Replaces substring\n    - default(value): Sets default if value is undefined\n    - first: Gets first character/item\n    - last: Gets last character/item\n    - length: Gets length of string/list\n    - sort: Sorts list\n    - join(delimiter): Joins list with delimiter\n',
    )

    def __init__(self, **kwargs: typing.Any) -> None:
        """
        Initialize a FormatText node.

        Extra keyword arguments beyond the defined fields will be treated as
        dynamic properties and automatically passed to the underlying BaseNode
        as dynamic_properties.

        Args:
            **kwargs: Field values and dynamic properties.
        """
        # Separate known fields from dynamic properties
        from pydantic import ConfigDict

        super().__init__(**kwargs)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.FormatText

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class HasLength(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Checks if text length meets specified conditions.
    text, check, length, compare, validate, whitespace, string

    Use cases:
    - Validating input length requirements
    - Filtering text by length
    - Checking content size constraints
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    min_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    max_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    exact_length: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.HasLength

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class HtmlToText(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Converts HTML content to plain text using html2text.
    html, convert, text, parse, extract

    Use cases:
    - Converting HTML documents to readable plain text
    - Extracting text content from web pages
    - Cleaning HTML markup from text data
    - Processing HTML emails or documents
    """

    html: str | OutputHandle[str] = connect_field(
        default="", description="HTML content to convert"
    )
    base_url: str | OutputHandle[str] = connect_field(
        default="", description="Base URL for resolving relative links"
    )
    body_width: int | OutputHandle[int] = connect_field(
        default=1000, description="Width for text wrapping"
    )
    ignore_images: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to ignore image tags"
    )
    ignore_mailto_links: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to ignore mailto links"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.HtmlToText

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class IsEmpty(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Checks if text is empty or contains only whitespace.
    text, check, empty, compare, validate, whitespace, string

    Use cases:
    - Validating required text fields
    - Filtering out empty content
    - Checking for meaningful input
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    trim_whitespace: bool | OutputHandle[bool] = connect_field(
        default=True, description=None
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.IsEmpty

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Join(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Joins a list of strings into a single string using a specified separator.
    text, join, combine, +, add, concatenate

    Use cases:
    - Combining multiple text elements with a consistent delimiter
    - Creating comma-separated lists from individual items
    - Assembling formatted text from array elements
    """

    strings: list[str] | OutputHandle[list[str]] = connect_field(
        default=[], description=None
    )
    separator: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Join

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class LoadTextAssets(GraphNode[nodetool.nodes.nodetool.text.LoadTextAssets.OutputType]):
    """
    Load text files from an asset folder.
    load, text, file, import

    Use cases:
    - Loading multiple text files for batch processing
    - Importing text content from a directory
    - Processing collections of text documents
    """

    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(
        default=types.FolderRef(type="folder", uri="", asset_id=None, data=None),
        description="The asset folder to load the text files from.",
    )

    @property
    def out(self) -> "LoadTextAssetsOutputs":
        return LoadTextAssetsOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.LoadTextAssets

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class LoadTextAssetsOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[types.TextRef]:
        return typing.cast(OutputHandle[types.TextRef], self["text"])

    @property
    def name(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["name"])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class ParseJSON(SingleOutputGraphNode[Any], GraphNode[Any]):
    """
    Parses a JSON string into a Python object.
    json, parse, convert

    Use cases:
    - Converting JSON API responses for further processing
    - Preparing structured data for analysis or storage
    - Extracting configuration or settings from JSON files
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.ParseJSON

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class RegexMatch(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Find all matches of a regex pattern in text.
    regex, search, pattern, match

    Use cases:
    - Extract specific patterns from text
    - Validate text against patterns
    - Find all occurrences of a pattern
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to search in"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )
    group: int | OutputHandle[int] | None = connect_field(
        default=None, description="Capture group to extract (0 for full match)"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.RegexMatch

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class RegexReplace(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Replace text matching a regex pattern.
    regex, replace, substitute

    Use cases:
    - Clean or standardize text
    - Remove unwanted patterns
    - Transform text formats
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to perform replacements on"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )
    replacement: str | OutputHandle[str] = connect_field(
        default="", description="Replacement text"
    )
    count: int | OutputHandle[int] = connect_field(
        default=0, description="Maximum replacements (0 for unlimited)"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.RegexReplace

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class RegexSplit(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Split text using a regex pattern as delimiter.
    regex, split, tokenize

    Use cases:
    - Parse structured text
    - Extract fields from formatted strings
    - Tokenize text
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to split"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern to split on"
    )
    maxsplit: int | OutputHandle[int] = connect_field(
        default=0, description="Maximum number of splits (0 for unlimited)"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.RegexSplit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class RegexValidate(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Check if text matches a regex pattern.
    regex, validate, check

    Use cases:
    - Validate input formats (email, phone, etc)
    - Check text structure
    - Filter text based on patterns
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to validate"
    )
    pattern: str | OutputHandle[str] = connect_field(
        default="", description="Regular expression pattern"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.RegexValidate

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Replace(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Replaces a substring in a text with another substring.
    text, replace, substitute

    Use cases:
    - Correcting or updating specific text patterns
    - Sanitizing or normalizing text data
    - Implementing simple text transformations
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    old: str | OutputHandle[str] = connect_field(default="", description=None)
    new: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Replace

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class SaveText(SingleOutputGraphNode[types.TextRef], GraphNode[types.TextRef]):
    """
    Saves input text to a file in the assets folder.
    text, save, file

    Use cases:
    - Persisting processed text results
    - Creating text files for downstream nodes or external use
    - Archiving text data within the workflow
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(
        default=types.FolderRef(type="folder", uri="", asset_id=None, data=None),
        description="Name of the output folder.",
    )
    name: str | OutputHandle[str] = connect_field(
        default="%Y-%m-%d-%H-%M-%S.txt",
        description="\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.SaveText

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class SaveTextFile(SingleOutputGraphNode[types.TextRef], GraphNode[types.TextRef]):
    """
    Saves input text to a file in the assets folder.
    text, save, file
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    folder: str | OutputHandle[str] = connect_field(
        default="", description="Path to the output folder."
    )
    name: str | OutputHandle[str] = connect_field(
        default="%Y-%m-%d-%H-%M-%S.txt",
        description="\n        Name of the output file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.SaveTextFile

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Slice(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Slices text using Python's slice notation (start:stop:step).
    text, slice, substring

    Use cases:
    - Extracting specific portions of text with flexible indexing
    - Reversing text using negative step
    - Taking every nth character with step parameter

    Examples:
    - start=0, stop=5: first 5 characters
    - start=-5: last 5 characters
    - step=2: every second character
    - step=-1: reverse the text
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    start: int | OutputHandle[int] | None = connect_field(
        default=None, description=None
    )
    stop: int | OutputHandle[int] | None = connect_field(default=None, description=None)
    step: int | OutputHandle[int] | None = connect_field(default=None, description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Slice

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Split(SingleOutputGraphNode[list[str]], GraphNode[list[str]]):
    """
    Separates text into a list of strings based on a specified delimiter.
    text, split, tokenize

    Use cases:
    - Parsing CSV or similar delimited data
    - Breaking down sentences into words or phrases
    - Extracting specific elements from structured text
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    delimiter: str | OutputHandle[str] = connect_field(default=",", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Split

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class StartsWith(SingleOutputGraphNode[bool], GraphNode[bool]):
    """
    Checks if text starts with a specified prefix.
    text, check, prefix, compare, validate, substring, string

    Use cases:
    - Validating string prefixes
    - Filtering text based on starting content
    - Checking file name patterns
    """

    text: str | OutputHandle[str] = connect_field(default="", description=None)
    prefix: str | OutputHandle[str] = connect_field(default="", description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.StartsWith

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.text
from nodetool.workflows.base_node import BaseNode


class Template(SingleOutputGraphNode[str], GraphNode[str]):
    """
    Uses Jinja2 templating to format strings with variables and filters. This node is dynamic and can be used to format text with dynamic inputs.
    text, template, formatting, format, combine, concatenate, +, add, variable, replace, filter

    Use cases:
    - Generating personalized messages with dynamic content
    - Creating parameterized queries or commands
    - Formatting and filtering text output based on variable inputs

    Examples:
    - text: "Hello, {{ name }}!"
    - text: "Title: {{ title|truncate(20) }}"
    - text: "Name: {{ name|upper }}"

    Available filters:
    - truncate(length): Truncates text to given length
    - upper: Converts text to uppercase
    - lower: Converts text to lowercase
    - title: Converts text to title case
    - trim: Removes whitespace from start/end
    - replace(old, new): Replaces substring
    - default(value): Sets default if value is undefined
    - first: Gets first character/item
    - last: Gets last character/item
    - length: Gets length of string/list
    - sort: Sorts list
    - join(delimiter): Joins list with delimiter


    This node supports dynamic properties. Additional properties can be passed
    as keyword arguments during initialization and will be stored in the node's
    dynamic_properties dictionary.

    Example:
        node = Template(prop1=value1, prop2=value2)
    """

    string: str | OutputHandle[str] = connect_field(
        default="",
        description='\n    Examples:\n    - text: "Hello, {{ name }}!"\n    - text: "Title: {{ title|truncate(20) }}"\n    - text: "Name: {{ name|upper }}"\n\n    Available filters:\n    - truncate(length): Truncates text to given length\n    - upper: Converts text to uppercase\n    - lower: Converts text to lowercase\n    - title: Converts text to title case\n    - trim: Removes whitespace from start/end\n    - replace(old, new): Replaces substring\n    - default(value): Sets default if value is undefined\n    - first: Gets first character/item\n    - last: Gets last character/item\n    - length: Gets length of string/list\n    - sort: Sorts list\n    - join(delimiter): Joins list with delimiter\n',
    )
    values: Any | OutputHandle[Any] = connect_field(
        default={},
        description="\n        The values to replace in the string.\n        - If a string, it will be used as the format string.\n        - If a list, it will be used as the format arguments.\n        - If a dictionary, it will be used as the template variables.\n        - If an object, it will be converted to a dictionary using the object's __dict__ method.\n        ",
    )

    def __init__(self, **kwargs: typing.Any) -> None:
        """
        Initialize a Template node.

        Extra keyword arguments beyond the defined fields will be treated as
        dynamic properties and automatically passed to the underlying BaseNode
        as dynamic_properties.

        Args:
            **kwargs: Field values and dynamic properties.
        """
        # Separate known fields from dynamic properties
        from pydantic import ConfigDict

        super().__init__(**kwargs)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.text.Template

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
