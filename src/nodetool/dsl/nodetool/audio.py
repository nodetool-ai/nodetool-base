# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class AudioMixer(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Mix up to 5 audio tracks together with individual volume controls.
        audio, mix, volume, combine, blend, layer, add, overlay
    """

    track1: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='First audio track to mix.')
    track2: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='Second audio track to mix.')
    track3: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='Third audio track to mix.')
    track4: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='Fourth audio track to mix.')
    track5: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='Fifth audio track to mix.')
    volume1: float | OutputHandle[float] = connect_field(default=1.0, description='Volume for track 1. 1.0 is original volume.')
    volume2: float | OutputHandle[float] = connect_field(default=1.0, description='Volume for track 2. 1.0 is original volume.')
    volume3: float | OutputHandle[float] = connect_field(default=1.0, description='Volume for track 3. 1.0 is original volume.')
    volume4: float | OutputHandle[float] = connect_field(default=1.0, description='Volume for track 4. 1.0 is original volume.')
    volume5: float | OutputHandle[float] = connect_field(default=1.0, description='Volume for track 5. 1.0 is original volume.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.AudioMixer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class AudioToNumpy(GraphNode[nodetool.nodes.nodetool.audio.AudioToNumpy.OutputType]):
    """

        Convert audio to numpy array for processing.
        audio, numpy, convert, array
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio to convert to numpy.')

    @property
    def out(self) -> "AudioToNumpyOutputs":
        return AudioToNumpyOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.AudioToNumpy

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

class AudioToNumpyOutputs(OutputsProxy):
    @property
    def array(self) -> OutputHandle[types.NPArray]:
        return typing.cast(OutputHandle[types.NPArray], self['array'])

    @property
    def sample_rate(self) -> OutputHandle[int]:
        return typing.cast(OutputHandle[int], self['sample_rate'])

    @property
    def channels(self) -> OutputHandle[int]:
        return typing.cast(OutputHandle[int], self['channels'])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class ChunkToAudio(GraphNode[nodetool.nodes.nodetool.audio.ChunkToAudio.OutputType]):
    """

        Aggregates audio chunks from an input stream into AudioRef objects.
        audio, stream, chunk, aggregate, collect, batch
    """

    chunk: types.Chunk | OutputHandle[types.Chunk] = connect_field(default=types.Chunk(type='chunk', node_id=None, thread_id=None, workflow_id=None, content_type='text', content='', content_metadata={}, done=False), description='Stream of audio chunks')
    batch_size: int | OutputHandle[int] = connect_field(default=50, description='Number of chunks to aggregate per output')

    @property
    def out(self) -> "ChunkToAudioOutputs":
        return ChunkToAudioOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.ChunkToAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

class ChunkToAudioOutputs(OutputsProxy):
    @property
    def audio(self) -> OutputHandle[types.AudioRef]:
        return typing.cast(OutputHandle[types.AudioRef], self['audio'])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class Concat(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Concatenates two audio files together.
        audio, edit, join, +
    """

    a: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The first audio file.')
    b: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The second audio file.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.Concat

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class ConcatList(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Concatenates multiple audio files together in sequence.
        audio, edit, join, multiple, +
    """

    audio_files: list[types.AudioRef] | OutputHandle[list[types.AudioRef]] = connect_field(default=[], description='List of audio files to concatenate in sequence.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.ConcatList

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class ConvertToArray(SingleOutputGraphNode[types.NPArray], GraphNode[types.NPArray]):
    """

        Converts an audio file to a Array for further processing.
        audio, conversion, tensor
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to convert to a tensor.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.ConvertToArray

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class CreateSilence(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Creates a silent audio file with a specified duration.
        audio, silence, empty
    """

    duration: float | OutputHandle[float] = connect_field(default=1.0, description='The duration of the silence in seconds.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.CreateSilence

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class FadeIn(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Applies a fade-in effect to the beginning of an audio file.
        audio, edit, transition
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to apply fade-in to.')
    duration: float | OutputHandle[float] = connect_field(default=1.0, description='Duration of the fade-in effect in seconds.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.FadeIn

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class FadeOut(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Applies a fade-out effect to the end of an audio file.
        audio, edit, transition
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to apply fade-out to.')
    duration: float | OutputHandle[float] = connect_field(default=1.0, description='Duration of the fade-out effect in seconds.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.FadeOut

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class LoadAudioAssets(GraphNode[nodetool.nodes.nodetool.audio.LoadAudioAssets.OutputType]):
    """

        Load audio files from an asset folder.
        load, audio, file, import
    """

    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(default=types.FolderRef(type='folder', uri='', asset_id=None, data=None, metadata=None), description='The asset folder to load the audio files from.')

    @property
    def out(self) -> "LoadAudioAssetsOutputs":
        return LoadAudioAssetsOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.LoadAudioAssets

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

class LoadAudioAssetsOutputs(OutputsProxy):
    @property
    def audio(self) -> OutputHandle[types.AudioRef]:
        return typing.cast(OutputHandle[types.AudioRef], self['audio'])

    @property
    def name(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self['name'])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class LoadAudioFile(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Read an audio file from disk.
        audio, input, load, file
    """

    path: str | OutputHandle[str] = connect_field(default='', description='Path to the audio file to read')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.LoadAudioFile

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class LoadAudioFolder(GraphNode[nodetool.nodes.nodetool.audio.LoadAudioFolder.OutputType]):
    """

        Load all audio files from a folder, optionally including subfolders.
        audio, load, folder, files
    """

    folder: str | OutputHandle[str] = connect_field(default='', description='Folder to scan for audio files')
    include_subdirectories: bool | OutputHandle[bool] = connect_field(default=False, description='Include audio in subfolders')
    extensions: list[str] | OutputHandle[list[str]] = connect_field(default=['.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac'], description='Audio file extensions to include')

    @property
    def out(self) -> "LoadAudioFolderOutputs":
        return LoadAudioFolderOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.LoadAudioFolder

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

class LoadAudioFolderOutputs(OutputsProxy):
    @property
    def audio(self) -> OutputHandle[types.AudioRef]:
        return typing.cast(OutputHandle[types.AudioRef], self['audio'])

    @property
    def path(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self['path'])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class MonoToStereo(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Converts a mono audio signal to stereo.
        audio, convert, channels
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The mono audio file to convert.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.MonoToStereo

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class Normalize(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Normalizes the volume of an audio file.
        audio, fix, dynamics, volume
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to normalize.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.Normalize

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class NumpyToAudio(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Convert numpy array to audio.
        audio, numpy, convert
    """

    array: types.NPArray | OutputHandle[types.NPArray] = connect_field(default=types.NPArray(type='np_array', value=None, dtype='<i8', shape=(1,)), description='The numpy array to convert to audio.')
    sample_rate: int | OutputHandle[int] = connect_field(default=44100, description='Sample rate in Hz.')
    channels: int | OutputHandle[int] = connect_field(default=1, description='Number of audio channels (1 or 2).')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.NumpyToAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class OverlayAudio(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Overlays two audio files together.
        audio, edit, transform
    """

    a: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The first audio file.')
    b: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The second audio file.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.OverlayAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class RemoveSilence(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Removes or shortens silence in an audio file with smooth transitions.
        audio, edit, clean
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to process.')
    min_length: int | OutputHandle[int] = connect_field(default=200, description='Minimum length of silence to be processed (in milliseconds).')
    threshold: int | OutputHandle[int] = connect_field(default=-40, description='Silence threshold in dB (relative to full scale). Higher values detect more silence.')
    reduction_factor: float | OutputHandle[float] = connect_field(default=1.0, description='Factor to reduce silent parts (0.0 to 1.0). 0.0 keeps silence as is, 1.0 removes it completely.')
    crossfade: int | OutputHandle[int] = connect_field(default=10, description='Duration of crossfade in milliseconds to apply between segments for smooth transitions.')
    min_silence_between_parts: int | OutputHandle[int] = connect_field(default=100, description='Minimum silence duration in milliseconds to maintain between non-silent segments')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.RemoveSilence

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class Repeat(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Loops an audio file a specified number of times.
        audio, edit, repeat
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to loop.')
    loops: int | OutputHandle[int] = connect_field(default=2, description='Number of times to loop the audio. Minimum 1 (plays once), maximum 100.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.Repeat

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class Reverse(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Reverses an audio file.
        audio, edit, transform
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to reverse.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.Reverse

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class SaveAudio(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Save an audio file to a specified asset folder.
        audio, folder, name
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description=None)
    folder: types.FolderRef | OutputHandle[types.FolderRef] = connect_field(default=types.FolderRef(type='folder', uri='', asset_id=None, data=None, metadata=None), description='The asset folder to save the audio file to. ')
    name: str | OutputHandle[str] = connect_field(default='%Y-%m-%d-%H-%M-%S.opus', description='\n        The name of the audio file.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.SaveAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class SaveAudioFile(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Write an audio file to disk.
        audio, output, save, file

        The filename can include time and date variables:
        %Y - Year, %m - Month, %d - Day
        %H - Hour, %M - Minute, %S - Second

        Supported formats: mp3, wav, ogg, flac, aac, m4a
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio to save')
    folder: str | OutputHandle[str] = connect_field(default='', description='Folder where the file will be saved')
    filename: str | OutputHandle[str] = connect_field(default='', description='\n        Name of the file to save.\n        You can use time and date variables to create unique names:\n        %Y - Year\n        %m - Month\n        %d - Day\n        %H - Hour\n        %M - Minute\n        %S - Second\n        ')
    FORMAT_MAP: dict[str, str] | OutputHandle[dict[str, str]] = connect_field(default={'.mp3': 'mp3', '.wav': 'wav', '.ogg': 'ogg', '.flac': 'flac', '.aac': 'adts', '.m4a': 'ipod'}, description=None)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.SaveAudioFile

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class SliceAudio(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Extracts a section of an audio file.
        audio, edit, trim
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file.')
    start: float | OutputHandle[float] = connect_field(default=0.0, description='The start time in seconds.')
    end: float | OutputHandle[float] = connect_field(default=1.0, description='The end time in seconds.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.SliceAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class StereoToMono(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Converts a stereo audio signal to mono.
        audio, convert, channels
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The stereo audio file to convert.')
    method: str | OutputHandle[str] = connect_field(default='average', description="Method to use for conversion: 'average', 'left', or 'right'.")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.StereoToMono

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class TextToSpeech(GraphNode[nodetool.nodes.nodetool.audio.TextToSpeech.OutputType]):
    """

        Generate speech audio from text using any supported TTS provider. Automatically routes to the appropriate backend (OpenAI, HuggingFace, MLX).
        audio, generation, AI, text-to-speech, tts, voice
    """

    model: types.TTSModel | OutputHandle[types.TTSModel] = connect_field(default=types.TTSModel(type='tts_model', provider=nodetool.metadata.types.Provider.OpenAI, id='tts-1', name='TTS 1', path=None, voices=['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'], selected_voice=''), description='The text-to-speech model to use')
    text: str | OutputHandle[str] = connect_field(default='Hello! This is a text-to-speech demonstration.', description='Text to convert to speech')
    speed: float | OutputHandle[float] = connect_field(default=1.0, description='Speech speed multiplier (0.25 to 4.0)')

    @property
    def out(self) -> "TextToSpeechOutputs":
        return TextToSpeechOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.TextToSpeech

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()

class TextToSpeechOutputs(OutputsProxy):
    @property
    def audio(self) -> OutputHandle[nodetool.metadata.types.AudioRef]:
        return typing.cast(OutputHandle[nodetool.metadata.types.AudioRef], self['audio'])

    @property
    def chunk(self) -> OutputHandle[types.Chunk]:
        return typing.cast(OutputHandle[types.Chunk], self['chunk'])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.nodetool.audio
from nodetool.workflows.base_node import BaseNode

class Trim(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

        Trim an audio file to a specified duration.
        audio, trim, cut
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(default=types.AudioRef(type='audio', uri='', asset_id=None, data=None, metadata=None), description='The audio file to trim.')
    start: float | OutputHandle[float] = connect_field(default=0.0, description='The start time of the trimmed audio in seconds.')
    end: float | OutputHandle[float] = connect_field(default=0.0, description='The end time of the trimmed audio in seconds.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.nodetool.audio.Trim

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


