# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import (
    OutputHandle,
    OutputsProxy,
    DynamicOutputsProxy,
    connect_field,
)
import nodetool.nodes.openai.agents
from nodetool.workflows.base_node import BaseNode


class RealtimeAgent(GraphNode[nodetool.nodes.openai.agents.RealtimeAgent.OutputType]):
    """

    Stream responses using the official OpenAI Realtime client. Supports optional audio input and streams text chunks.
    realtime, streaming, openai, audio-input, text-output

    Uses `AsyncOpenAI().beta.realtime.connect(...)` with the events API:
    - Sends session settings via `session.update`
    - Adds user input via `conversation.item.create`
    - Streams back `response.text.delta` events until `response.done`
    """

    Model: typing.ClassVar[type] = nodetool.nodes.openai.agents.RealtimeAgent.Model
    Voice: typing.ClassVar[type] = nodetool.nodes.openai.agents.RealtimeAgent.Voice

    model: nodetool.nodes.openai.agents.RealtimeAgent.Model = Field(
        default=nodetool.nodes.openai.agents.RealtimeAgent.Model.GPT_4O_MINI_REaltime,
        description=None,
    )
    system: str | OutputHandle[str] = connect_field(
        default="\nYou are an AI assistant interacting in real-time. Follow these rules unless explicitly overridden by the user:\n\n1. Respond promptly — minimize delay. If you do not yet have a complete answer, acknowledge the question and indicate what you are doing to find the answer.\n2. Maintain correctness. Always aim for accuracy; if you’re uncertain, say so and optionally offer to verify.\n3. Be concise but clear. Prioritize key information first, then supporting details if helpful.\n4. Ask clarifying questions when needed. If the user’s request is ambiguous, request clarification rather than guessing.\n5. Be consistent in terminology and definitions. Once you adopt a term or abbreviation, use it consistently in this conversation.\n6. Respect politeness and neutrality. Do not use emotive language unless the conversation tone demands it.\n7. Stay within safe and ethical bounds. Avoid disallowed content; follow OpenAI policies.\n8. Adapt to the user’s style and level. If the user seems technical, use technical detail; if non-technical, explain with simpler language.\n---\nYou are now active. Await the user’s request.\n",
        description="System instructions for the realtime session",
    )
    chunk: types.Chunk | OutputHandle[types.Chunk] = connect_field(
        default=types.Chunk(
            type="chunk",
            node_id=None,
            content_type="text",
            content="",
            content_metadata={},
            done=False,
        ),
        description="The audio chunk to use as input.",
    )
    voice: nodetool.nodes.openai.agents.RealtimeAgent.Voice = Field(
        default=nodetool.nodes.openai.agents.RealtimeAgent.Voice.ALLOY,
        description="The voice for the audio output",
    )
    speed: float | OutputHandle[float] = connect_field(
        default=1.0, description="The speed of the model's spoken response"
    )
    temperature: float | OutputHandle[float] = connect_field(
        default=0.8, description="The temperature for the response"
    )

    def __init__(
        self,
        *,
        dynamic_outputs: dict[str, typing.Any] | None = None,
        **kwargs: typing.Any,
    ) -> None:
        """
        Initialize a RealtimeAgent node.

        Dynamic outputs declared here will be forwarded to the underlying node
        so they are available when the workflow executes. Provide Python types
        such as str or list[int] for each output.

        Args:
            dynamic_outputs: Optional mapping from output names to Python types.
            **kwargs: Field values for the node.
        """

        outputs = {} if dynamic_outputs is None else dict(dynamic_outputs)
        super().__init__(dynamic_outputs=outputs, **kwargs)

    @property
    def out(self) -> "RealtimeAgentOutputs":
        return RealtimeAgentOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.openai.agents.RealtimeAgent

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class RealtimeAgentOutputs(DynamicOutputsProxy):
    @property
    def chunk(self) -> OutputHandle[types.Chunk]:
        return typing.cast(OutputHandle[types.Chunk], self["chunk"])

    @property
    def audio(self) -> OutputHandle[nodetool.metadata.types.AudioRef]:
        return typing.cast(
            OutputHandle[nodetool.metadata.types.AudioRef], self["audio"]
        )

    @property
    def text(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["text"])


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.openai.agents
from nodetool.workflows.base_node import BaseNode


class RealtimeTranscription(
    GraphNode[nodetool.nodes.openai.agents.RealtimeTranscription.OutputType]
):
    """

    Stream microphone or audio input to OpenAI Realtime and emit transcription.

    Emits:
      - `chunk` Chunk(content=..., done=False) for transcript deltas
      - `chunk` Chunk(content="", done=True) to mark segment end
      - `text` final aggregated transcript when input ends
    """

    model: types.LanguageModel | OutputHandle[types.LanguageModel] = connect_field(
        default=types.LanguageModel(
            type="language_model",
            provider=nodetool.metadata.types.Provider.Empty,
            id="",
            name="",
        ),
        description="Model to use",
    )
    system: str | OutputHandle[str] = connect_field(
        default="", description="System instructions (optional)"
    )
    temperature: float | OutputHandle[float] = connect_field(
        default=0.8, description="Decoding temperature"
    )

    @property
    def out(self) -> "RealtimeTranscriptionOutputs":
        return RealtimeTranscriptionOutputs(self)

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.openai.agents.RealtimeTranscription

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


class RealtimeTranscriptionOutputs(OutputsProxy):
    @property
    def text(self) -> OutputHandle[str]:
        return typing.cast(OutputHandle[str], self["text"])

    @property
    def chunk(self) -> OutputHandle[types.Chunk]:
        return typing.cast(OutputHandle[types.Chunk], self["chunk"])
